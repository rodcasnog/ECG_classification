{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biosppy.signals.ecg as ecg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "extraction_directory = 'extracted_images/'\n",
    "y_train = pd.read_csv(extraction_directory + 'y_train.csv', index_col='id')\n",
    "X_train = pd.read_csv(extraction_directory + 'X_train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 59.21%\n",
      "Class 1: 8.66%\n",
      "Class 2: 28.81%\n",
      "Class 3: 3.32%\n"
     ]
    }
   ],
   "source": [
    "class_distribution = y_train.apply(lambda x: {'Class ' + str(i): x[x == i].count() / X_train.shape[0] for i in range(4)})['y']\n",
    "for name in class_distribution:\n",
    "    print(name + ': {:.2%}'.format(class_distribution[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "4613    1230\n",
       "2384    1245\n",
       "1941    1251\n",
       "3754    1252\n",
       "589     1305\n",
       "        ... \n",
       "922     8837\n",
       "985     8840\n",
       "2102    8855\n",
       "971     8856\n",
       "3273    8904\n",
       "Length: 5117, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_downsampled = X_train.iloc[:,range(0, X_train.shape[1], 2)]\n",
    "\n",
    "measure_length_downsampled = (-X_train_downsampled.T.isna()).sum().sort_values(ascending=True)\n",
    "\n",
    "measure_length_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06910896301269531\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "length = measure_length_downsampled.iloc[0]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "X_train1_np = np.zeros((measure_length_downsampled.shape[0], length))\n",
    "X_train_downsampled_np = X_train_downsampled.to_numpy()\n",
    "\n",
    "for ind in range(X_train_downsampled.shape[0]):\n",
    "    first_timestep = (measure_length_downsampled.loc[X_train_downsampled.index[ind]] - length) // 2\n",
    "    last_timestep = first_timestep + length\n",
    "    X_train1_np[ind,:] = X_train_downsampled_np[ind,first_timestep:last_timestep]\n",
    "\n",
    "X_train1 = pd.DataFrame(data=X_train1_np, index=X_train_downsampled.index)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_transformed_np = scaler.fit_transform(X_train1.to_numpy())\n",
    "\n",
    "X_train_transformed = pd.DataFrame(data=X_train_transformed_np, index=X_train1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcasado/Desktop/Rodrigo_work/Universidad/PhD/Other/Coding/Visual Studio Code/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, BatchNormalization, Dropout, Conv1D, Flatten, MaxPooling1D, Input, Concatenate\n",
    "from keras.metrics import AUC\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical\n",
    "y_train_cat_np = to_categorical(y_train.to_numpy())\n",
    "\n",
    "# Split data\n",
    "X_train_partial, X_val, y_train_partial, y_val = train_test_split(X_train_transformed_np, y_train_cat_np, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers=[32, 16, 16, 24, 16, 8, 3], train_examples=4093, val_examples=1024\n",
      "batch = 4093, timesteps = 1230, features = 1, epochs = 150\n",
      "learning_rate = 0.005, lambda = 0.003, dropout = 0.4, recurrent_dropout = 0.0\n"
     ]
    }
   ],
   "source": [
    "T = X_train_partial.shape[1]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [32, 16, 16, 24, 16, 8, 3]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_partial.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_val.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "BATCH = M_TRAIN# // 8                          # batch size\n",
    "EPOCH = 150                          # number of epochs\n",
    "learning_rate = 5e-3                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-3                         # lambda in L2 regularizaion\n",
    "dropout = 0.4                             # dropout rate\n",
    "dropout_CNN = .5\n",
    "recurrent_dropout = 0.0                            # recurrent dropout rate\n",
    "print(f'layers={LAYERS}, train_examples={M_TRAIN}, val_examples={M_TEST}')\n",
    "print(f'batch = {BATCH}, timesteps = {T}, features = {1}, epochs = {EPOCH}')\n",
    "print(f'learning_rate = {learning_rate}, lambda = {LAMBD}, dropout = {dropout}, recurrent_dropout = {recurrent_dropout}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1228, 32)          128       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1228, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 614, 32)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 610, 64)           10304     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 610, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 305, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 299, 64)           28736     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 299, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 149, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 139, 64)           45120     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 139, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 69, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 57, 64)            53312     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 57, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 28, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 14, 64)            61504     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 14, 64)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 896)               0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 896)               3584      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 48)                43056     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 48)                192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 48)                2352      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 48)                192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                784       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 249396 (974.20 KB)\n",
      "Trainable params: 247380 (966.33 KB)\n",
      "Non-trainable params: 2016 (7.88 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the Model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(T,1)))\n",
    "model.add(Dropout(dropout_CNN))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(Dropout(dropout_CNN))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=7, activation='relu'))\n",
    "model.add(Dropout(dropout_CNN))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=11, activation='relu'))\n",
    "model.add(Dropout(dropout_CNN))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=13, activation='relu'))\n",
    "model.add(Dropout(dropout_CNN))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=15, activation='relu'))\n",
    "model.add(Dropout(dropout_CNN))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=48, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(units=48, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],#, AUC()],#[f1_score],\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate))\n",
    "print(model.summary())\n",
    "\n",
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1,\n",
    "                             verbose=0, \n",
    "                             factor=0.5,\n",
    "                             min_lr=1e-8)\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_accuracy',\n",
    "                           min_delta=0, \n",
    "                           patience=1500,\n",
    "                           verbose=1,\n",
    "                           mode='auto',\n",
    "                           baseline=0,\n",
    "                           restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.8998 - accuracy: 0.2209 - val_loss: 1.3794 - val_accuracy: 0.4883\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7982 - accuracy: 0.2311 - val_loss: 1.4530 - val_accuracy: 0.0410\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7188 - accuracy: 0.2228 - val_loss: 1.7272 - val_accuracy: 0.0391\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6704 - accuracy: 0.2402 - val_loss: 2.2266 - val_accuracy: 0.0400\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6155 - accuracy: 0.2634 - val_loss: 2.5466 - val_accuracy: 0.0420\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5929 - accuracy: 0.2563 - val_loss: 2.9163 - val_accuracy: 0.0439\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5484 - accuracy: 0.2670 - val_loss: 2.9131 - val_accuracy: 0.0518\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5284 - accuracy: 0.2863 - val_loss: 2.8508 - val_accuracy: 0.0684\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4982 - accuracy: 0.2983 - val_loss: 2.7433 - val_accuracy: 0.0947\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4741 - accuracy: 0.3049 - val_loss: 2.5121 - val_accuracy: 0.1309\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4282 - accuracy: 0.3223 - val_loss: 2.3247 - val_accuracy: 0.1953\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4361 - accuracy: 0.3526 - val_loss: 2.1720 - val_accuracy: 0.2676\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3750 - accuracy: 0.3733 - val_loss: 2.0721 - val_accuracy: 0.3223\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3715 - accuracy: 0.3816 - val_loss: 1.9776 - val_accuracy: 0.3740\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3700 - accuracy: 0.4193 - val_loss: 1.8922 - val_accuracy: 0.4023\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3279 - accuracy: 0.4527 - val_loss: 1.7979 - val_accuracy: 0.4258\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3224 - accuracy: 0.4740 - val_loss: 1.7252 - val_accuracy: 0.4502\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3408 - accuracy: 0.4794 - val_loss: 1.6584 - val_accuracy: 0.4717\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2995 - accuracy: 0.5045 - val_loss: 1.5919 - val_accuracy: 0.4893\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2902 - accuracy: 0.5199 - val_loss: 1.5414 - val_accuracy: 0.5010\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2839 - accuracy: 0.5338 - val_loss: 1.4907 - val_accuracy: 0.5107\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2727 - accuracy: 0.5392 - val_loss: 1.4393 - val_accuracy: 0.5225\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2548 - accuracy: 0.5478 - val_loss: 1.3972 - val_accuracy: 0.5303\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2388 - accuracy: 0.5614 - val_loss: 1.3577 - val_accuracy: 0.5410\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2226 - accuracy: 0.5676 - val_loss: 1.3283 - val_accuracy: 0.5469\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2315 - accuracy: 0.5676 - val_loss: 1.3014 - val_accuracy: 0.5547\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2294 - accuracy: 0.5727 - val_loss: 1.2761 - val_accuracy: 0.5586\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2262 - accuracy: 0.5702 - val_loss: 1.2530 - val_accuracy: 0.5615\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2093 - accuracy: 0.5788 - val_loss: 1.2319 - val_accuracy: 0.5635\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1883 - accuracy: 0.5832 - val_loss: 1.2105 - val_accuracy: 0.5635\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1740 - accuracy: 0.5827 - val_loss: 1.1904 - val_accuracy: 0.5703\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1924 - accuracy: 0.5805 - val_loss: 1.1726 - val_accuracy: 0.5713\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1760 - accuracy: 0.5781 - val_loss: 1.1554 - val_accuracy: 0.5762\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1539 - accuracy: 0.5837 - val_loss: 1.1404 - val_accuracy: 0.5781\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1510 - accuracy: 0.5878 - val_loss: 1.1265 - val_accuracy: 0.5752\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1627 - accuracy: 0.5800 - val_loss: 1.1144 - val_accuracy: 0.5752\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1471 - accuracy: 0.5854 - val_loss: 1.1035 - val_accuracy: 0.5771\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1359 - accuracy: 0.5878 - val_loss: 1.0938 - val_accuracy: 0.5781\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1174 - accuracy: 0.5866 - val_loss: 1.0850 - val_accuracy: 0.5811\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1455 - accuracy: 0.5844 - val_loss: 1.0774 - val_accuracy: 0.5791\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1207 - accuracy: 0.5883 - val_loss: 1.0705 - val_accuracy: 0.5791\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1089 - accuracy: 0.5876 - val_loss: 1.0648 - val_accuracy: 0.5791\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1182 - accuracy: 0.5895 - val_loss: 1.0597 - val_accuracy: 0.5771\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0998 - accuracy: 0.5905 - val_loss: 1.0553 - val_accuracy: 0.5801\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0883 - accuracy: 0.5881 - val_loss: 1.0512 - val_accuracy: 0.5791\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0882 - accuracy: 0.5891 - val_loss: 1.0476 - val_accuracy: 0.5791\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1085 - accuracy: 0.5905 - val_loss: 1.0445 - val_accuracy: 0.5791\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0826 - accuracy: 0.5891 - val_loss: 1.0421 - val_accuracy: 0.5801\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0780 - accuracy: 0.5903 - val_loss: 1.0396 - val_accuracy: 0.5791\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0678 - accuracy: 0.5883 - val_loss: 1.0370 - val_accuracy: 0.5791\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0802 - accuracy: 0.5908 - val_loss: 1.0347 - val_accuracy: 0.5801\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0822 - accuracy: 0.5908 - val_loss: 1.0324 - val_accuracy: 0.5801\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0564 - accuracy: 0.5908 - val_loss: 1.0302 - val_accuracy: 0.5811\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1000 - accuracy: 0.5893 - val_loss: 1.0281 - val_accuracy: 0.5820\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0765 - accuracy: 0.5915 - val_loss: 1.0262 - val_accuracy: 0.5830\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0612 - accuracy: 0.5947 - val_loss: 1.0244 - val_accuracy: 0.5820\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0376 - accuracy: 0.5935 - val_loss: 1.0228 - val_accuracy: 0.5820\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0707 - accuracy: 0.5915 - val_loss: 1.0212 - val_accuracy: 0.5820\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0501 - accuracy: 0.5920 - val_loss: 1.0199 - val_accuracy: 0.5820\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0561 - accuracy: 0.5913 - val_loss: 1.0186 - val_accuracy: 0.5820\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0385 - accuracy: 0.5913 - val_loss: 1.0175 - val_accuracy: 0.5820\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0226 - accuracy: 0.5957 - val_loss: 1.0164 - val_accuracy: 0.5820\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0452 - accuracy: 0.5932 - val_loss: 1.0155 - val_accuracy: 0.5820\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0542 - accuracy: 0.5927 - val_loss: 1.0148 - val_accuracy: 0.5811\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0526 - accuracy: 0.5927 - val_loss: 1.0142 - val_accuracy: 0.5811\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0354 - accuracy: 0.5944 - val_loss: 1.0137 - val_accuracy: 0.5811\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0534 - accuracy: 0.5922 - val_loss: 1.0131 - val_accuracy: 0.5811\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0513 - accuracy: 0.5942 - val_loss: 1.0127 - val_accuracy: 0.5811\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0443 - accuracy: 0.5942 - val_loss: 1.0123 - val_accuracy: 0.5820\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0476 - accuracy: 0.5947 - val_loss: 1.0119 - val_accuracy: 0.5820\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0141 - accuracy: 0.5925 - val_loss: 1.0115 - val_accuracy: 0.5820\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0205 - accuracy: 0.5922 - val_loss: 1.0111 - val_accuracy: 0.5820\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0430 - accuracy: 0.5930 - val_loss: 1.0108 - val_accuracy: 0.5820\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0180 - accuracy: 0.5947 - val_loss: 1.0105 - val_accuracy: 0.5820\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0237 - accuracy: 0.5920 - val_loss: 1.0103 - val_accuracy: 0.5820\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0154 - accuracy: 0.5942 - val_loss: 1.0102 - val_accuracy: 0.5820\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0184 - accuracy: 0.5925 - val_loss: 1.0100 - val_accuracy: 0.5820\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0069 - accuracy: 0.5944 - val_loss: 1.0098 - val_accuracy: 0.5820\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0184 - accuracy: 0.5932 - val_loss: 1.0097 - val_accuracy: 0.5820\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0276 - accuracy: 0.5947 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0129 - accuracy: 0.5925 - val_loss: 1.0094 - val_accuracy: 0.5820\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0091 - accuracy: 0.5942 - val_loss: 1.0093 - val_accuracy: 0.5820\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0129 - accuracy: 0.5930 - val_loss: 1.0091 - val_accuracy: 0.5820\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0132 - accuracy: 0.5949 - val_loss: 1.0090 - val_accuracy: 0.5820\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0020 - accuracy: 0.5937 - val_loss: 1.0089 - val_accuracy: 0.5820\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0203 - accuracy: 0.5952 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0245 - accuracy: 0.5927 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0114 - accuracy: 0.5935 - val_loss: 1.0086 - val_accuracy: 0.5820\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0307 - accuracy: 0.5944 - val_loss: 1.0085 - val_accuracy: 0.5820\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0350 - accuracy: 0.5961 - val_loss: 1.0085 - val_accuracy: 0.5820\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0166 - accuracy: 0.5954 - val_loss: 1.0086 - val_accuracy: 0.5820\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0206 - accuracy: 0.5949 - val_loss: 1.0086 - val_accuracy: 0.5820\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0369 - accuracy: 0.5927 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0175 - accuracy: 0.5937 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0031 - accuracy: 0.5942 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0031 - accuracy: 0.5942 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0008 - accuracy: 0.5952 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0043 - accuracy: 0.5939 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9940 - accuracy: 0.5927 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0141 - accuracy: 0.5942 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0020 - accuracy: 0.5966 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0357 - accuracy: 0.5932 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0247 - accuracy: 0.5930 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0134 - accuracy: 0.5932 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0010 - accuracy: 0.5947 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0091 - accuracy: 0.5930 - val_loss: 1.0086 - val_accuracy: 0.5820\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0088 - accuracy: 0.5974 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0199 - accuracy: 0.5927 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9905 - accuracy: 0.5954 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9897 - accuracy: 0.5959 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0000 - accuracy: 0.5959 - val_loss: 1.0087 - val_accuracy: 0.5820\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0273 - accuracy: 0.5913 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9983 - accuracy: 0.5930 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0059 - accuracy: 0.5932 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0041 - accuracy: 0.5947 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9989 - accuracy: 0.5981 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0039 - accuracy: 0.5932 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0000 - accuracy: 0.5949 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9851 - accuracy: 0.5949 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9965 - accuracy: 0.5961 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9933 - accuracy: 0.5939 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9902 - accuracy: 0.5959 - val_loss: 1.0088 - val_accuracy: 0.5820\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9882 - accuracy: 0.5930 - val_loss: 1.0089 - val_accuracy: 0.5820\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0013 - accuracy: 0.5957 - val_loss: 1.0089 - val_accuracy: 0.5820\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9912 - accuracy: 0.5966 - val_loss: 1.0090 - val_accuracy: 0.5820\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9962 - accuracy: 0.5971 - val_loss: 1.0091 - val_accuracy: 0.5820\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9904 - accuracy: 0.5949 - val_loss: 1.0092 - val_accuracy: 0.5820\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9945 - accuracy: 0.5952 - val_loss: 1.0093 - val_accuracy: 0.5820\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9960 - accuracy: 0.5947 - val_loss: 1.0094 - val_accuracy: 0.5820\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9962 - accuracy: 0.5957 - val_loss: 1.0095 - val_accuracy: 0.5820\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9900 - accuracy: 0.5952 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9863 - accuracy: 0.5959 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9907 - accuracy: 0.5939 - val_loss: 1.0098 - val_accuracy: 0.5820\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0056 - accuracy: 0.5964 - val_loss: 1.0099 - val_accuracy: 0.5820\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9950 - accuracy: 0.5957 - val_loss: 1.0100 - val_accuracy: 0.5820\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9941 - accuracy: 0.5949 - val_loss: 1.0101 - val_accuracy: 0.5820\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0115 - accuracy: 0.5971 - val_loss: 1.0101 - val_accuracy: 0.5820\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9971 - accuracy: 0.5954 - val_loss: 1.0102 - val_accuracy: 0.5820\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9908 - accuracy: 0.5957 - val_loss: 1.0102 - val_accuracy: 0.5820\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9944 - accuracy: 0.5986 - val_loss: 1.0101 - val_accuracy: 0.5820\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0031 - accuracy: 0.5949 - val_loss: 1.0100 - val_accuracy: 0.5820\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0306 - accuracy: 0.5952 - val_loss: 1.0099 - val_accuracy: 0.5820\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0015 - accuracy: 0.5952 - val_loss: 1.0098 - val_accuracy: 0.5820\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0075 - accuracy: 0.5942 - val_loss: 1.0097 - val_accuracy: 0.5820\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9877 - accuracy: 0.5964 - val_loss: 1.0097 - val_accuracy: 0.5820\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9974 - accuracy: 0.5930 - val_loss: 1.0097 - val_accuracy: 0.5820\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0004 - accuracy: 0.5957 - val_loss: 1.0098 - val_accuracy: 0.5820\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0119 - accuracy: 0.5964 - val_loss: 1.0097 - val_accuracy: 0.5820\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9892 - accuracy: 0.5969 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9998 - accuracy: 0.5937 - val_loss: 1.0098 - val_accuracy: 0.5820\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0148 - accuracy: 0.5922 - val_loss: 1.0099 - val_accuracy: 0.5820\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0008 - accuracy: 0.5947 - val_loss: 1.0100 - val_accuracy: 0.5820\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9986 - accuracy: 0.5947 - val_loss: 1.0101 - val_accuracy: 0.5820\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9917 - accuracy: 0.5954 - val_loss: 1.0102 - val_accuracy: 0.5820\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0120 - accuracy: 0.5957 - val_loss: 1.0103 - val_accuracy: 0.5820\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9963 - accuracy: 0.5969 - val_loss: 1.0104 - val_accuracy: 0.5820\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9874 - accuracy: 0.5935 - val_loss: 1.0104 - val_accuracy: 0.5820\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0061 - accuracy: 0.5944 - val_loss: 1.0105 - val_accuracy: 0.5820\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9941 - accuracy: 0.5937 - val_loss: 1.0106 - val_accuracy: 0.5820\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0104 - accuracy: 0.5944 - val_loss: 1.0106 - val_accuracy: 0.5820\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9865 - accuracy: 0.5947 - val_loss: 1.0105 - val_accuracy: 0.5820\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0064 - accuracy: 0.5942 - val_loss: 1.0105 - val_accuracy: 0.5820\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9948 - accuracy: 0.5947 - val_loss: 1.0104 - val_accuracy: 0.5820\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9985 - accuracy: 0.5952 - val_loss: 1.0103 - val_accuracy: 0.5820\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9847 - accuracy: 0.5939 - val_loss: 1.0102 - val_accuracy: 0.5820\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0214 - accuracy: 0.5942 - val_loss: 1.0102 - val_accuracy: 0.5820\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0107 - accuracy: 0.5935 - val_loss: 1.0101 - val_accuracy: 0.5820\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9889 - accuracy: 0.5932 - val_loss: 1.0100 - val_accuracy: 0.5820\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9818 - accuracy: 0.5961 - val_loss: 1.0099 - val_accuracy: 0.5820\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9830 - accuracy: 0.5947 - val_loss: 1.0099 - val_accuracy: 0.5820\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9875 - accuracy: 0.5969 - val_loss: 1.0099 - val_accuracy: 0.5820\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0026 - accuracy: 0.5952 - val_loss: 1.0098 - val_accuracy: 0.5820\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0096 - accuracy: 0.5954 - val_loss: 1.0098 - val_accuracy: 0.5820\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0334 - accuracy: 0.5935 - val_loss: 1.0097 - val_accuracy: 0.5820\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9815 - accuracy: 0.5966 - val_loss: 1.0097 - val_accuracy: 0.5820\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9882 - accuracy: 0.5957 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0011 - accuracy: 0.5952 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9993 - accuracy: 0.5961 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9946 - accuracy: 0.5949 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9837 - accuracy: 0.5947 - val_loss: 1.0096 - val_accuracy: 0.5820\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9871 - accuracy: 0.5949 - val_loss: 1.0097 - val_accuracy: 0.5820\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9965 - accuracy: 0.5937 - val_loss: 1.0098 - val_accuracy: 0.5820\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9814 - accuracy: 0.5974 - val_loss: 1.0099 - val_accuracy: 0.5820\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9875 - accuracy: 0.5959 - val_loss: 1.0100 - val_accuracy: 0.5820\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9972 - accuracy: 0.5974 - val_loss: 1.0102 - val_accuracy: 0.5820\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9947 - accuracy: 0.5957 - val_loss: 1.0103 - val_accuracy: 0.5820\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9877 - accuracy: 0.5947 - val_loss: 1.0105 - val_accuracy: 0.5820\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9797 - accuracy: 0.5966 - val_loss: 1.0106 - val_accuracy: 0.5820\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9974 - accuracy: 0.5969 - val_loss: 1.0108 - val_accuracy: 0.5820\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9809 - accuracy: 0.5957 - val_loss: 1.0110 - val_accuracy: 0.5820\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0021 - accuracy: 0.5964 - val_loss: 1.0112 - val_accuracy: 0.5820\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9881 - accuracy: 0.5944 - val_loss: 1.0114 - val_accuracy: 0.5820\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9979 - accuracy: 0.5976 - val_loss: 1.0116 - val_accuracy: 0.5820\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9883 - accuracy: 0.5969 - val_loss: 1.0119 - val_accuracy: 0.5820\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9931 - accuracy: 0.5954 - val_loss: 1.0121 - val_accuracy: 0.5820\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9915 - accuracy: 0.5959 - val_loss: 1.0122 - val_accuracy: 0.5820\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9808 - accuracy: 0.5957 - val_loss: 1.0123 - val_accuracy: 0.5820\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0010 - accuracy: 0.5954 - val_loss: 1.0123 - val_accuracy: 0.5820\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9884 - accuracy: 0.5964 - val_loss: 1.0122 - val_accuracy: 0.5820\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9852 - accuracy: 0.5959 - val_loss: 1.0122 - val_accuracy: 0.5820\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9923 - accuracy: 0.5957 - val_loss: 1.0120 - val_accuracy: 0.5820\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9852 - accuracy: 0.5947 - val_loss: 1.0119 - val_accuracy: 0.5820\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9879 - accuracy: 0.5961 - val_loss: 1.0118 - val_accuracy: 0.5820\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9820 - accuracy: 0.5964 - val_loss: 1.0118 - val_accuracy: 0.5820\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9954 - accuracy: 0.5949 - val_loss: 1.0118 - val_accuracy: 0.5820\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9943 - accuracy: 0.5964 - val_loss: 1.0119 - val_accuracy: 0.5820\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9869 - accuracy: 0.5959 - val_loss: 1.0120 - val_accuracy: 0.5820\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9964 - accuracy: 0.5971 - val_loss: 1.0120 - val_accuracy: 0.5820\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9792 - accuracy: 0.5976 - val_loss: 1.0119 - val_accuracy: 0.5820\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9834 - accuracy: 0.5961 - val_loss: 1.0119 - val_accuracy: 0.5820\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9833 - accuracy: 0.5939 - val_loss: 1.0118 - val_accuracy: 0.5820\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9799 - accuracy: 0.5957 - val_loss: 1.0118 - val_accuracy: 0.5820\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9826 - accuracy: 0.5922 - val_loss: 1.0117 - val_accuracy: 0.5820\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9759 - accuracy: 0.5964 - val_loss: 1.0117 - val_accuracy: 0.5820\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0003 - accuracy: 0.5964 - val_loss: 1.0116 - val_accuracy: 0.5820\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9777 - accuracy: 0.5959 - val_loss: 1.0115 - val_accuracy: 0.5820\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9766 - accuracy: 0.5961 - val_loss: 1.0115 - val_accuracy: 0.5820\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0072 - accuracy: 0.5969 - val_loss: 1.0114 - val_accuracy: 0.5820\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9916 - accuracy: 0.5978 - val_loss: 1.0115 - val_accuracy: 0.5820\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9720 - accuracy: 0.5981 - val_loss: 1.0115 - val_accuracy: 0.5820\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9762 - accuracy: 0.5966 - val_loss: 1.0116 - val_accuracy: 0.5820\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9871 - accuracy: 0.5969 - val_loss: 1.0119 - val_accuracy: 0.5820\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9929 - accuracy: 0.5939 - val_loss: 1.0121 - val_accuracy: 0.5820\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9804 - accuracy: 0.5957 - val_loss: 1.0123 - val_accuracy: 0.5820\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9826 - accuracy: 0.5969 - val_loss: 1.0121 - val_accuracy: 0.5820\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9773 - accuracy: 0.5957 - val_loss: 1.0122 - val_accuracy: 0.5820\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9922 - accuracy: 0.5974 - val_loss: 1.0123 - val_accuracy: 0.5820\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9856 - accuracy: 0.5957 - val_loss: 1.0125 - val_accuracy: 0.5820\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9802 - accuracy: 0.5966 - val_loss: 1.0127 - val_accuracy: 0.5820\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9799 - accuracy: 0.5971 - val_loss: 1.0129 - val_accuracy: 0.5820\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9852 - accuracy: 0.5954 - val_loss: 1.0131 - val_accuracy: 0.5820\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9808 - accuracy: 0.5971 - val_loss: 1.0133 - val_accuracy: 0.5820\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9861 - accuracy: 0.5969 - val_loss: 1.0134 - val_accuracy: 0.5820\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9799 - accuracy: 0.5954 - val_loss: 1.0136 - val_accuracy: 0.5820\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9774 - accuracy: 0.5964 - val_loss: 1.0136 - val_accuracy: 0.5820\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9833 - accuracy: 0.5952 - val_loss: 1.0137 - val_accuracy: 0.5820\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9788 - accuracy: 0.5961 - val_loss: 1.0139 - val_accuracy: 0.5820\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9735 - accuracy: 0.5966 - val_loss: 1.0140 - val_accuracy: 0.5820\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9815 - accuracy: 0.5952 - val_loss: 1.0141 - val_accuracy: 0.5820\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9714 - accuracy: 0.5974 - val_loss: 1.0143 - val_accuracy: 0.5820\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9945 - accuracy: 0.5966 - val_loss: 1.0144 - val_accuracy: 0.5820\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9793 - accuracy: 0.5986 - val_loss: 1.0145 - val_accuracy: 0.5820\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9806 - accuracy: 0.5952 - val_loss: 1.0147 - val_accuracy: 0.5820\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9724 - accuracy: 0.5969 - val_loss: 1.0148 - val_accuracy: 0.5820\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9978 - accuracy: 0.5954 - val_loss: 1.0149 - val_accuracy: 0.5820\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9853 - accuracy: 0.5969 - val_loss: 1.0151 - val_accuracy: 0.5820\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9802 - accuracy: 0.5949 - val_loss: 1.0152 - val_accuracy: 0.5820\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9894 - accuracy: 0.5944 - val_loss: 1.0151 - val_accuracy: 0.5820\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9770 - accuracy: 0.5971 - val_loss: 1.0150 - val_accuracy: 0.5820\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9669 - accuracy: 0.5986 - val_loss: 1.0149 - val_accuracy: 0.5820\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9834 - accuracy: 0.5939 - val_loss: 1.0152 - val_accuracy: 0.5820\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9785 - accuracy: 0.5944 - val_loss: 1.0158 - val_accuracy: 0.5820\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9885 - accuracy: 0.5954 - val_loss: 1.0162 - val_accuracy: 0.5820\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9761 - accuracy: 0.5954 - val_loss: 1.0166 - val_accuracy: 0.5820\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9758 - accuracy: 0.5942 - val_loss: 1.0171 - val_accuracy: 0.5820\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9781 - accuracy: 0.5983 - val_loss: 1.0175 - val_accuracy: 0.5820\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9913 - accuracy: 0.5947 - val_loss: 1.0178 - val_accuracy: 0.5820\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9888 - accuracy: 0.5959 - val_loss: 1.0156 - val_accuracy: 0.5820\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9820 - accuracy: 0.5942 - val_loss: 1.0176 - val_accuracy: 0.5820\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9778 - accuracy: 0.5959 - val_loss: 1.0174 - val_accuracy: 0.5820\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9739 - accuracy: 0.5961 - val_loss: 1.0174 - val_accuracy: 0.5820\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9727 - accuracy: 0.5969 - val_loss: 1.0183 - val_accuracy: 0.5820\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9782 - accuracy: 0.5974 - val_loss: 1.0185 - val_accuracy: 0.5820\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9793 - accuracy: 0.5961 - val_loss: 1.0184 - val_accuracy: 0.5820\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9660 - accuracy: 0.5959 - val_loss: 1.0234 - val_accuracy: 0.5820\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9763 - accuracy: 0.5969 - val_loss: 1.0191 - val_accuracy: 0.5820\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9788 - accuracy: 0.5961 - val_loss: 1.0180 - val_accuracy: 0.5820\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9895 - accuracy: 0.5949 - val_loss: 1.0180 - val_accuracy: 0.5820\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9878 - accuracy: 0.5944 - val_loss: 1.0178 - val_accuracy: 0.5820\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9765 - accuracy: 0.5966 - val_loss: 1.0179 - val_accuracy: 0.5820\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9956 - accuracy: 0.5957 - val_loss: 1.0179 - val_accuracy: 0.5820\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9751 - accuracy: 0.5957 - val_loss: 1.0176 - val_accuracy: 0.5820\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9805 - accuracy: 0.5964 - val_loss: 1.0175 - val_accuracy: 0.5820\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9833 - accuracy: 0.5966 - val_loss: 1.0172 - val_accuracy: 0.5820\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9827 - accuracy: 0.5991 - val_loss: 1.0169 - val_accuracy: 0.5820\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9759 - accuracy: 0.5949 - val_loss: 1.0166 - val_accuracy: 0.5820\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9661 - accuracy: 0.5969 - val_loss: 1.0167 - val_accuracy: 0.5820\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9802 - accuracy: 0.5954 - val_loss: 1.0165 - val_accuracy: 0.5820\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9901 - accuracy: 0.5954 - val_loss: 1.0164 - val_accuracy: 0.5820\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9685 - accuracy: 0.5974 - val_loss: 1.0164 - val_accuracy: 0.5820\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9767 - accuracy: 0.5976 - val_loss: 1.0165 - val_accuracy: 0.5820\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9856 - accuracy: 0.5988 - val_loss: 1.0166 - val_accuracy: 0.5820\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9900 - accuracy: 0.5959 - val_loss: 1.0166 - val_accuracy: 0.5820\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9817 - accuracy: 0.5954 - val_loss: 1.0165 - val_accuracy: 0.5820\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9705 - accuracy: 0.5981 - val_loss: 1.0165 - val_accuracy: 0.5820\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9713 - accuracy: 0.5988 - val_loss: 1.0165 - val_accuracy: 0.5820\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9825 - accuracy: 0.5952 - val_loss: 1.0166 - val_accuracy: 0.5820\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9830 - accuracy: 0.5966 - val_loss: 1.0166 - val_accuracy: 0.5820\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9815 - accuracy: 0.5964 - val_loss: 1.0167 - val_accuracy: 0.5820\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9780 - accuracy: 0.5961 - val_loss: 1.0168 - val_accuracy: 0.5820\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9663 - accuracy: 0.5964 - val_loss: 1.0169 - val_accuracy: 0.5820\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9704 - accuracy: 0.5976 - val_loss: 1.0171 - val_accuracy: 0.5820\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9723 - accuracy: 0.5966 - val_loss: 1.0171 - val_accuracy: 0.5820\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9668 - accuracy: 0.5959 - val_loss: 1.0172 - val_accuracy: 0.5820\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9842 - accuracy: 0.5957 - val_loss: 1.0172 - val_accuracy: 0.5820\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9846 - accuracy: 0.5981 - val_loss: 1.0172 - val_accuracy: 0.5820\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9794 - accuracy: 0.5966 - val_loss: 1.0172 - val_accuracy: 0.5820\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9688 - accuracy: 0.5991 - val_loss: 1.0173 - val_accuracy: 0.5820\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9689 - accuracy: 0.5978 - val_loss: 1.0173 - val_accuracy: 0.5820\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9703 - accuracy: 0.5976 - val_loss: 1.0174 - val_accuracy: 0.5820\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9666 - accuracy: 0.5978 - val_loss: 1.0175 - val_accuracy: 0.5820\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9759 - accuracy: 0.5966 - val_loss: 1.0176 - val_accuracy: 0.5820\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9683 - accuracy: 0.5986 - val_loss: 1.0177 - val_accuracy: 0.5820\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9686 - accuracy: 0.5981 - val_loss: 1.0178 - val_accuracy: 0.5820\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9729 - accuracy: 0.5981 - val_loss: 1.0179 - val_accuracy: 0.5820\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9772 - accuracy: 0.5942 - val_loss: 1.0179 - val_accuracy: 0.5820\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9739 - accuracy: 0.5957 - val_loss: 1.0180 - val_accuracy: 0.5820\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9728 - accuracy: 0.5976 - val_loss: 1.0180 - val_accuracy: 0.5820\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9703 - accuracy: 0.5976 - val_loss: 1.0181 - val_accuracy: 0.5820\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9680 - accuracy: 0.5966 - val_loss: 1.0182 - val_accuracy: 0.5820\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9700 - accuracy: 0.5964 - val_loss: 1.0184 - val_accuracy: 0.5820\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9692 - accuracy: 0.5978 - val_loss: 1.0185 - val_accuracy: 0.5820\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9749 - accuracy: 0.5981 - val_loss: 1.0187 - val_accuracy: 0.5820\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9741 - accuracy: 0.5978 - val_loss: 1.0189 - val_accuracy: 0.5820\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9640 - accuracy: 0.5952 - val_loss: 1.0191 - val_accuracy: 0.5820\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9787 - accuracy: 0.5961 - val_loss: 1.0192 - val_accuracy: 0.5820\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9759 - accuracy: 0.5966 - val_loss: 1.0194 - val_accuracy: 0.5820\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9663 - accuracy: 0.5991 - val_loss: 1.0195 - val_accuracy: 0.5820\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9756 - accuracy: 0.5969 - val_loss: 1.0196 - val_accuracy: 0.5820\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9653 - accuracy: 0.5983 - val_loss: 1.0198 - val_accuracy: 0.5820\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9615 - accuracy: 0.5978 - val_loss: 1.0202 - val_accuracy: 0.5820\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9681 - accuracy: 0.5959 - val_loss: 1.0205 - val_accuracy: 0.5820\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9720 - accuracy: 0.5971 - val_loss: 1.0207 - val_accuracy: 0.5820\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9755 - accuracy: 0.5986 - val_loss: 1.0209 - val_accuracy: 0.5820\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9656 - accuracy: 0.5978 - val_loss: 1.0212 - val_accuracy: 0.5820\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9674 - accuracy: 0.5978 - val_loss: 1.0214 - val_accuracy: 0.5820\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9623 - accuracy: 0.5966 - val_loss: 1.0217 - val_accuracy: 0.5820\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9632 - accuracy: 0.5981 - val_loss: 1.0218 - val_accuracy: 0.5820\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9608 - accuracy: 0.5976 - val_loss: 1.0219 - val_accuracy: 0.5820\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9636 - accuracy: 0.5981 - val_loss: 1.0221 - val_accuracy: 0.5820\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9725 - accuracy: 0.5971 - val_loss: 1.0222 - val_accuracy: 0.5820\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9781 - accuracy: 0.5966 - val_loss: 1.0223 - val_accuracy: 0.5820\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9612 - accuracy: 0.5988 - val_loss: 1.0224 - val_accuracy: 0.5820\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9638 - accuracy: 0.5978 - val_loss: 1.0226 - val_accuracy: 0.5820\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9643 - accuracy: 0.5976 - val_loss: 1.0227 - val_accuracy: 0.5820\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9734 - accuracy: 0.5964 - val_loss: 1.0229 - val_accuracy: 0.5820\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9641 - accuracy: 0.5959 - val_loss: 1.0231 - val_accuracy: 0.5820\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9593 - accuracy: 0.5988 - val_loss: 1.0233 - val_accuracy: 0.5820\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9762 - accuracy: 0.5981 - val_loss: 1.0235 - val_accuracy: 0.5820\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9670 - accuracy: 0.5988 - val_loss: 1.0237 - val_accuracy: 0.5820\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9660 - accuracy: 0.5976 - val_loss: 1.0238 - val_accuracy: 0.5820\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9985 - accuracy: 0.5978 - val_loss: 1.0240 - val_accuracy: 0.5820\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9644 - accuracy: 0.5971 - val_loss: 1.0243 - val_accuracy: 0.5820\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9679 - accuracy: 0.5978 - val_loss: 1.0245 - val_accuracy: 0.5820\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9699 - accuracy: 0.5969 - val_loss: 1.0247 - val_accuracy: 0.5820\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9632 - accuracy: 0.6005 - val_loss: 1.0250 - val_accuracy: 0.5820\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9645 - accuracy: 0.5974 - val_loss: 1.0253 - val_accuracy: 0.5820\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9624 - accuracy: 0.5974 - val_loss: 1.0256 - val_accuracy: 0.5820\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9636 - accuracy: 0.5983 - val_loss: 1.0256 - val_accuracy: 0.5820\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9646 - accuracy: 0.5974 - val_loss: 1.0251 - val_accuracy: 0.5820\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9632 - accuracy: 0.5991 - val_loss: 1.0249 - val_accuracy: 0.5820\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9689 - accuracy: 0.5971 - val_loss: 1.0242 - val_accuracy: 0.5820\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9773 - accuracy: 0.5974 - val_loss: 1.0250 - val_accuracy: 0.5820\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9659 - accuracy: 0.5981 - val_loss: 1.0252 - val_accuracy: 0.5820\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9697 - accuracy: 0.5969 - val_loss: 1.0251 - val_accuracy: 0.5820\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9617 - accuracy: 0.5974 - val_loss: 1.0249 - val_accuracy: 0.5820\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9647 - accuracy: 0.5961 - val_loss: 1.0251 - val_accuracy: 0.5820\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9639 - accuracy: 0.5986 - val_loss: 1.0252 - val_accuracy: 0.5820\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9595 - accuracy: 0.5981 - val_loss: 1.0254 - val_accuracy: 0.5820\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9666 - accuracy: 0.5969 - val_loss: 1.0256 - val_accuracy: 0.5820\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9717 - accuracy: 0.5993 - val_loss: 1.0257 - val_accuracy: 0.5820\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9691 - accuracy: 0.5966 - val_loss: 1.0259 - val_accuracy: 0.5820\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9649 - accuracy: 0.5988 - val_loss: 1.0261 - val_accuracy: 0.5820\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9645 - accuracy: 0.5986 - val_loss: 1.0264 - val_accuracy: 0.5820\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9629 - accuracy: 0.5983 - val_loss: 1.0266 - val_accuracy: 0.5820\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9609 - accuracy: 0.5969 - val_loss: 1.0269 - val_accuracy: 0.5820\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9589 - accuracy: 0.5961 - val_loss: 1.0271 - val_accuracy: 0.5820\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9689 - accuracy: 0.5974 - val_loss: 1.0274 - val_accuracy: 0.5820\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9693 - accuracy: 0.5966 - val_loss: 1.0275 - val_accuracy: 0.5820\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9612 - accuracy: 0.5981 - val_loss: 1.0275 - val_accuracy: 0.5820\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9659 - accuracy: 0.5978 - val_loss: 1.0275 - val_accuracy: 0.5820\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9773 - accuracy: 0.5974 - val_loss: 1.0275 - val_accuracy: 0.5820\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9625 - accuracy: 0.5974 - val_loss: 1.0275 - val_accuracy: 0.5820\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9548 - accuracy: 0.5998 - val_loss: 1.0276 - val_accuracy: 0.5820\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9579 - accuracy: 0.5993 - val_loss: 1.0278 - val_accuracy: 0.5820\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9597 - accuracy: 0.5983 - val_loss: 1.0280 - val_accuracy: 0.5820\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9618 - accuracy: 0.5978 - val_loss: 1.0281 - val_accuracy: 0.5820\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9602 - accuracy: 0.5986 - val_loss: 1.0283 - val_accuracy: 0.5820\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9653 - accuracy: 0.5964 - val_loss: 1.0285 - val_accuracy: 0.5820\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9740 - accuracy: 0.5966 - val_loss: 1.0286 - val_accuracy: 0.5820\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9559 - accuracy: 0.6000 - val_loss: 1.0287 - val_accuracy: 0.5820\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9656 - accuracy: 0.5986 - val_loss: 1.0287 - val_accuracy: 0.5820\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9604 - accuracy: 0.5971 - val_loss: 1.0288 - val_accuracy: 0.5820\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9587 - accuracy: 0.5976 - val_loss: 1.0287 - val_accuracy: 0.5820\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9624 - accuracy: 0.5988 - val_loss: 1.0286 - val_accuracy: 0.5820\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9599 - accuracy: 0.5974 - val_loss: 1.0287 - val_accuracy: 0.5820\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9602 - accuracy: 0.5983 - val_loss: 1.0287 - val_accuracy: 0.5820\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9618 - accuracy: 0.5991 - val_loss: 1.0287 - val_accuracy: 0.5820\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9606 - accuracy: 0.5976 - val_loss: 1.0288 - val_accuracy: 0.5820\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9595 - accuracy: 0.5988 - val_loss: 1.0290 - val_accuracy: 0.5820\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9587 - accuracy: 0.5966 - val_loss: 1.0292 - val_accuracy: 0.5820\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9568 - accuracy: 0.5996 - val_loss: 1.0294 - val_accuracy: 0.5820\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9588 - accuracy: 0.5981 - val_loss: 1.0296 - val_accuracy: 0.5820\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9582 - accuracy: 0.6003 - val_loss: 1.0299 - val_accuracy: 0.5820\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9566 - accuracy: 0.5998 - val_loss: 1.0302 - val_accuracy: 0.5820\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9558 - accuracy: 0.5986 - val_loss: 1.0305 - val_accuracy: 0.5820\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9630 - accuracy: 0.5983 - val_loss: 1.0308 - val_accuracy: 0.5820\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9560 - accuracy: 0.6005 - val_loss: 1.0313 - val_accuracy: 0.5820\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9592 - accuracy: 0.6003 - val_loss: 1.0316 - val_accuracy: 0.5820\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9550 - accuracy: 0.5976 - val_loss: 1.0319 - val_accuracy: 0.5820\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9612 - accuracy: 0.5986 - val_loss: 1.0322 - val_accuracy: 0.5820\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9581 - accuracy: 0.6003 - val_loss: 1.0325 - val_accuracy: 0.5820\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9640 - accuracy: 0.5986 - val_loss: 1.0326 - val_accuracy: 0.5820\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9559 - accuracy: 0.5996 - val_loss: 1.0326 - val_accuracy: 0.5820\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9532 - accuracy: 0.5978 - val_loss: 1.0324 - val_accuracy: 0.5820\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9628 - accuracy: 0.5983 - val_loss: 1.0322 - val_accuracy: 0.5820\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9492 - accuracy: 0.6005 - val_loss: 1.0319 - val_accuracy: 0.5820\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9626 - accuracy: 0.5988 - val_loss: 1.0316 - val_accuracy: 0.5820\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9562 - accuracy: 0.6003 - val_loss: 1.0312 - val_accuracy: 0.5820\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9578 - accuracy: 0.5993 - val_loss: 1.0309 - val_accuracy: 0.5820\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9600 - accuracy: 0.5978 - val_loss: 1.0307 - val_accuracy: 0.5820\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9566 - accuracy: 0.5981 - val_loss: 1.0307 - val_accuracy: 0.5820\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9550 - accuracy: 0.5993 - val_loss: 1.0312 - val_accuracy: 0.5820\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9535 - accuracy: 0.6005 - val_loss: 1.0316 - val_accuracy: 0.5820\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9568 - accuracy: 0.5971 - val_loss: 1.0322 - val_accuracy: 0.5820\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9574 - accuracy: 0.5981 - val_loss: 1.0328 - val_accuracy: 0.5820\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9524 - accuracy: 0.5986 - val_loss: 1.0336 - val_accuracy: 0.5820\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9513 - accuracy: 0.6010 - val_loss: 1.0343 - val_accuracy: 0.5820\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9554 - accuracy: 0.6020 - val_loss: 1.0351 - val_accuracy: 0.5820\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9550 - accuracy: 0.5998 - val_loss: 1.0358 - val_accuracy: 0.5820\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9572 - accuracy: 0.5993 - val_loss: 1.0363 - val_accuracy: 0.5820\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9560 - accuracy: 0.5991 - val_loss: 1.0369 - val_accuracy: 0.5820\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9587 - accuracy: 0.6008 - val_loss: 1.0375 - val_accuracy: 0.5820\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9488 - accuracy: 0.6000 - val_loss: 1.0381 - val_accuracy: 0.5820\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9566 - accuracy: 0.5988 - val_loss: 1.0385 - val_accuracy: 0.5820\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9553 - accuracy: 0.5993 - val_loss: 1.0390 - val_accuracy: 0.5820\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9611 - accuracy: 0.5991 - val_loss: 1.0392 - val_accuracy: 0.5820\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9543 - accuracy: 0.6010 - val_loss: 1.0393 - val_accuracy: 0.5820\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9567 - accuracy: 0.5983 - val_loss: 1.0394 - val_accuracy: 0.5820\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9537 - accuracy: 0.6000 - val_loss: 1.0394 - val_accuracy: 0.5820\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9532 - accuracy: 0.6003 - val_loss: 1.0393 - val_accuracy: 0.5820\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9511 - accuracy: 0.6005 - val_loss: 1.0392 - val_accuracy: 0.5820\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9509 - accuracy: 0.6013 - val_loss: 1.0391 - val_accuracy: 0.5820\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9541 - accuracy: 0.5993 - val_loss: 1.0386 - val_accuracy: 0.5820\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9525 - accuracy: 0.5993 - val_loss: 1.0380 - val_accuracy: 0.5820\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9571 - accuracy: 0.5981 - val_loss: 1.0369 - val_accuracy: 0.5820\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9470 - accuracy: 0.5993 - val_loss: 1.0364 - val_accuracy: 0.5820\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9545 - accuracy: 0.5996 - val_loss: 1.0359 - val_accuracy: 0.5820\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9505 - accuracy: 0.5988 - val_loss: 1.0356 - val_accuracy: 0.5820\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9452 - accuracy: 0.6010 - val_loss: 1.0356 - val_accuracy: 0.5820\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9555 - accuracy: 0.5991 - val_loss: 1.0360 - val_accuracy: 0.5820\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9493 - accuracy: 0.6005 - val_loss: 1.0370 - val_accuracy: 0.5820\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9503 - accuracy: 0.5981 - val_loss: 1.0379 - val_accuracy: 0.5820\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9593 - accuracy: 0.6003 - val_loss: 1.0393 - val_accuracy: 0.5820\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9563 - accuracy: 0.6003 - val_loss: 1.0401 - val_accuracy: 0.5820\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9508 - accuracy: 0.6015 - val_loss: 1.0410 - val_accuracy: 0.5820\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9466 - accuracy: 0.6010 - val_loss: 1.0415 - val_accuracy: 0.5820\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9456 - accuracy: 0.6008 - val_loss: 1.0421 - val_accuracy: 0.5820\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9464 - accuracy: 0.6025 - val_loss: 1.0426 - val_accuracy: 0.5820\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9449 - accuracy: 0.6018 - val_loss: 1.0431 - val_accuracy: 0.5820\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9491 - accuracy: 0.6020 - val_loss: 1.0432 - val_accuracy: 0.5820\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9449 - accuracy: 0.6010 - val_loss: 1.0433 - val_accuracy: 0.5820\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9460 - accuracy: 0.5986 - val_loss: 1.0432 - val_accuracy: 0.5820\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9475 - accuracy: 0.6008 - val_loss: 1.0432 - val_accuracy: 0.5820\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9478 - accuracy: 0.5986 - val_loss: 1.0432 - val_accuracy: 0.5820\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9529 - accuracy: 0.5998 - val_loss: 1.0428 - val_accuracy: 0.5820\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9470 - accuracy: 0.6000 - val_loss: 1.0418 - val_accuracy: 0.5820\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9501 - accuracy: 0.5993 - val_loss: 1.0413 - val_accuracy: 0.5820\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9499 - accuracy: 0.6005 - val_loss: 1.0411 - val_accuracy: 0.5820\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9509 - accuracy: 0.5998 - val_loss: 1.0415 - val_accuracy: 0.5820\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9411 - accuracy: 0.6018 - val_loss: 1.0421 - val_accuracy: 0.5820\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9426 - accuracy: 0.6027 - val_loss: 1.0431 - val_accuracy: 0.5820\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9417 - accuracy: 0.6010 - val_loss: 1.0437 - val_accuracy: 0.5820\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9406 - accuracy: 0.6000 - val_loss: 1.0446 - val_accuracy: 0.5820\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9441 - accuracy: 0.5996 - val_loss: 1.0456 - val_accuracy: 0.5820\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9375 - accuracy: 0.6005 - val_loss: 1.0468 - val_accuracy: 0.5820\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9443 - accuracy: 0.6003 - val_loss: 1.0482 - val_accuracy: 0.5820\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9414 - accuracy: 0.5971 - val_loss: 1.0485 - val_accuracy: 0.5820\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9424 - accuracy: 0.6013 - val_loss: 1.0481 - val_accuracy: 0.5820\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9348 - accuracy: 0.5983 - val_loss: 1.0465 - val_accuracy: 0.5820\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9375 - accuracy: 0.5983 - val_loss: 1.0458 - val_accuracy: 0.5820\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9379 - accuracy: 0.5996 - val_loss: 1.0451 - val_accuracy: 0.5820\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9319 - accuracy: 0.6054 - val_loss: 1.0430 - val_accuracy: 0.5820\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9293 - accuracy: 0.6022 - val_loss: 1.0431 - val_accuracy: 0.5820\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9337 - accuracy: 0.5944 - val_loss: 1.0404 - val_accuracy: 0.5820\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9372 - accuracy: 0.6000 - val_loss: 1.0370 - val_accuracy: 0.5820\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9299 - accuracy: 0.6013 - val_loss: 1.0346 - val_accuracy: 0.5820\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9321 - accuracy: 0.6042 - val_loss: 1.0340 - val_accuracy: 0.5820\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9368 - accuracy: 0.6008 - val_loss: 1.0358 - val_accuracy: 0.5820\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9288 - accuracy: 0.6035 - val_loss: 1.0376 - val_accuracy: 0.5820\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9170 - accuracy: 0.6044 - val_loss: 1.0390 - val_accuracy: 0.5820\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9210 - accuracy: 0.6025 - val_loss: 1.0410 - val_accuracy: 0.5820\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9161 - accuracy: 0.6057 - val_loss: 1.0446 - val_accuracy: 0.5820\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9196 - accuracy: 0.6030 - val_loss: 1.0447 - val_accuracy: 0.5820\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9091 - accuracy: 0.6088 - val_loss: 1.0442 - val_accuracy: 0.5820\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9076 - accuracy: 0.6091 - val_loss: 1.0418 - val_accuracy: 0.5820\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9124 - accuracy: 0.6054 - val_loss: 1.0380 - val_accuracy: 0.5820\n",
      "Epoch 488/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9044 - accuracy: 0.6169 - val_loss: 1.0358 - val_accuracy: 0.5820\n",
      "Epoch 489/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9039 - accuracy: 0.6179 - val_loss: 1.0314 - val_accuracy: 0.5820\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8990 - accuracy: 0.6203 - val_loss: 1.0249 - val_accuracy: 0.5820\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8947 - accuracy: 0.6218 - val_loss: 1.0176 - val_accuracy: 0.5820\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8987 - accuracy: 0.6186 - val_loss: 1.0075 - val_accuracy: 0.5820\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8918 - accuracy: 0.6279 - val_loss: 0.9954 - val_accuracy: 0.5811\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8930 - accuracy: 0.6247 - val_loss: 0.9872 - val_accuracy: 0.5811\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9016 - accuracy: 0.6203 - val_loss: 0.9813 - val_accuracy: 0.5820\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8777 - accuracy: 0.6328 - val_loss: 0.9800 - val_accuracy: 0.5820\n",
      "Epoch 497/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8734 - accuracy: 0.6345 - val_loss: 0.9873 - val_accuracy: 0.5830\n",
      "Epoch 498/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8886 - accuracy: 0.6335 - val_loss: 0.9929 - val_accuracy: 0.5840\n",
      "Epoch 499/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8752 - accuracy: 0.6369 - val_loss: 1.0162 - val_accuracy: 0.5840\n",
      "Epoch 500/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8739 - accuracy: 0.6357 - val_loss: 1.0508 - val_accuracy: 0.5840\n",
      "Epoch 501/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8562 - accuracy: 0.6443 - val_loss: 1.1005 - val_accuracy: 0.5840\n",
      "Epoch 502/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8665 - accuracy: 0.6430 - val_loss: 1.1248 - val_accuracy: 0.5840\n",
      "Epoch 503/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8557 - accuracy: 0.6511 - val_loss: 1.1426 - val_accuracy: 0.5840\n",
      "Epoch 504/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8655 - accuracy: 0.6465 - val_loss: 1.1605 - val_accuracy: 0.5840\n",
      "Epoch 505/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8430 - accuracy: 0.6602 - val_loss: 1.1685 - val_accuracy: 0.5840\n",
      "Epoch 506/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8458 - accuracy: 0.6584 - val_loss: 1.1714 - val_accuracy: 0.5840\n",
      "Epoch 507/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8623 - accuracy: 0.6567 - val_loss: 1.1757 - val_accuracy: 0.5840\n",
      "Epoch 508/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8595 - accuracy: 0.6531 - val_loss: 1.1777 - val_accuracy: 0.5840\n",
      "Epoch 509/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8474 - accuracy: 0.6589 - val_loss: 1.1807 - val_accuracy: 0.5840\n",
      "Epoch 510/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8451 - accuracy: 0.6648 - val_loss: 1.1852 - val_accuracy: 0.5840\n",
      "Epoch 511/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8374 - accuracy: 0.6616 - val_loss: 1.1995 - val_accuracy: 0.5840\n",
      "Epoch 512/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8542 - accuracy: 0.6653 - val_loss: 1.2175 - val_accuracy: 0.5840\n",
      "Epoch 513/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8362 - accuracy: 0.6702 - val_loss: 1.2271 - val_accuracy: 0.5840\n",
      "Epoch 514/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8306 - accuracy: 0.6792 - val_loss: 1.2341 - val_accuracy: 0.5840\n",
      "Epoch 515/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8312 - accuracy: 0.6736 - val_loss: 1.2422 - val_accuracy: 0.5840\n",
      "Epoch 516/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8218 - accuracy: 0.6802 - val_loss: 1.2426 - val_accuracy: 0.5840\n",
      "Epoch 517/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8298 - accuracy: 0.6716 - val_loss: 1.2395 - val_accuracy: 0.5840\n",
      "Epoch 518/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8269 - accuracy: 0.6763 - val_loss: 1.2197 - val_accuracy: 0.5830\n",
      "Epoch 519/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8359 - accuracy: 0.6675 - val_loss: 1.2004 - val_accuracy: 0.5830\n",
      "Epoch 520/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8340 - accuracy: 0.6699 - val_loss: 1.1941 - val_accuracy: 0.5830\n",
      "Epoch 521/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8244 - accuracy: 0.6812 - val_loss: 1.1970 - val_accuracy: 0.5840\n",
      "Epoch 522/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8256 - accuracy: 0.6777 - val_loss: 1.2130 - val_accuracy: 0.5850\n",
      "Epoch 523/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8165 - accuracy: 0.6809 - val_loss: 1.2373 - val_accuracy: 0.5840\n",
      "Epoch 524/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8183 - accuracy: 0.6829 - val_loss: 1.2560 - val_accuracy: 0.5830\n",
      "Epoch 525/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8373 - accuracy: 0.6834 - val_loss: 1.2691 - val_accuracy: 0.5830\n",
      "Epoch 526/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8297 - accuracy: 0.6802 - val_loss: 1.2740 - val_accuracy: 0.5820\n",
      "Epoch 527/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8180 - accuracy: 0.6824 - val_loss: 1.2755 - val_accuracy: 0.5820\n",
      "Epoch 528/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8231 - accuracy: 0.6839 - val_loss: 1.2776 - val_accuracy: 0.5820\n",
      "Epoch 529/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8102 - accuracy: 0.6873 - val_loss: 1.2831 - val_accuracy: 0.5820\n",
      "Epoch 530/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8162 - accuracy: 0.6873 - val_loss: 1.2912 - val_accuracy: 0.5820\n",
      "Epoch 531/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8158 - accuracy: 0.6831 - val_loss: 1.3009 - val_accuracy: 0.5820\n",
      "Epoch 532/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8129 - accuracy: 0.6890 - val_loss: 1.3159 - val_accuracy: 0.5820\n",
      "Epoch 533/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8210 - accuracy: 0.6841 - val_loss: 1.3312 - val_accuracy: 0.5820\n",
      "Epoch 534/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8195 - accuracy: 0.6860 - val_loss: 1.3335 - val_accuracy: 0.5820\n",
      "Epoch 535/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8161 - accuracy: 0.6897 - val_loss: 1.3282 - val_accuracy: 0.5820\n",
      "Epoch 536/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8176 - accuracy: 0.6875 - val_loss: 1.3186 - val_accuracy: 0.5820\n",
      "Epoch 537/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8109 - accuracy: 0.6829 - val_loss: 1.3025 - val_accuracy: 0.5820\n",
      "Epoch 538/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8056 - accuracy: 0.6934 - val_loss: 1.2887 - val_accuracy: 0.5820\n",
      "Epoch 539/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8106 - accuracy: 0.6922 - val_loss: 1.2851 - val_accuracy: 0.5820\n",
      "Epoch 540/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8077 - accuracy: 0.6956 - val_loss: 1.2915 - val_accuracy: 0.5830\n",
      "Epoch 541/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8022 - accuracy: 0.6851 - val_loss: 1.3021 - val_accuracy: 0.5830\n",
      "Epoch 542/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8024 - accuracy: 0.6922 - val_loss: 1.3101 - val_accuracy: 0.5820\n",
      "Epoch 543/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8011 - accuracy: 0.7005 - val_loss: 1.3153 - val_accuracy: 0.5820\n",
      "Epoch 544/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8009 - accuracy: 0.6929 - val_loss: 1.3105 - val_accuracy: 0.5820\n",
      "Epoch 545/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8046 - accuracy: 0.6919 - val_loss: 1.3018 - val_accuracy: 0.5820\n",
      "Epoch 546/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8068 - accuracy: 0.6926 - val_loss: 1.2937 - val_accuracy: 0.5830\n",
      "Epoch 547/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7956 - accuracy: 0.6961 - val_loss: 1.2919 - val_accuracy: 0.5830\n",
      "Epoch 548/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7975 - accuracy: 0.6995 - val_loss: 1.2907 - val_accuracy: 0.5830\n",
      "Epoch 549/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7819 - accuracy: 0.7024 - val_loss: 1.2902 - val_accuracy: 0.5830\n",
      "Epoch 550/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7943 - accuracy: 0.7027 - val_loss: 1.2904 - val_accuracy: 0.5830\n",
      "Epoch 551/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7951 - accuracy: 0.6983 - val_loss: 1.2885 - val_accuracy: 0.5840\n",
      "Epoch 552/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7887 - accuracy: 0.6968 - val_loss: 1.2813 - val_accuracy: 0.5840\n",
      "Epoch 553/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8052 - accuracy: 0.7007 - val_loss: 1.2759 - val_accuracy: 0.5840\n",
      "Epoch 554/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7894 - accuracy: 0.7017 - val_loss: 1.2697 - val_accuracy: 0.5850\n",
      "Epoch 555/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7892 - accuracy: 0.6988 - val_loss: 1.2596 - val_accuracy: 0.5850\n",
      "Epoch 556/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7911 - accuracy: 0.7034 - val_loss: 1.2481 - val_accuracy: 0.5850\n",
      "Epoch 557/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7924 - accuracy: 0.7058 - val_loss: 1.2401 - val_accuracy: 0.5850\n",
      "Epoch 558/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7804 - accuracy: 0.7039 - val_loss: 1.2431 - val_accuracy: 0.5840\n",
      "Epoch 559/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7784 - accuracy: 0.7056 - val_loss: 1.2525 - val_accuracy: 0.5840\n",
      "Epoch 560/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7936 - accuracy: 0.7029 - val_loss: 1.2614 - val_accuracy: 0.5840\n",
      "Epoch 561/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7827 - accuracy: 0.7034 - val_loss: 1.2681 - val_accuracy: 0.5830\n",
      "Epoch 562/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7844 - accuracy: 0.7002 - val_loss: 1.2714 - val_accuracy: 0.5830\n",
      "Epoch 563/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7760 - accuracy: 0.7056 - val_loss: 1.2738 - val_accuracy: 0.5830\n",
      "Epoch 564/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7847 - accuracy: 0.7063 - val_loss: 1.2782 - val_accuracy: 0.5820\n",
      "Epoch 565/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7862 - accuracy: 0.7049 - val_loss: 1.2830 - val_accuracy: 0.5820\n",
      "Epoch 566/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7763 - accuracy: 0.7071 - val_loss: 1.2862 - val_accuracy: 0.5830\n",
      "Epoch 567/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7764 - accuracy: 0.6978 - val_loss: 1.2809 - val_accuracy: 0.5830\n",
      "Epoch 568/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7806 - accuracy: 0.7073 - val_loss: 1.2726 - val_accuracy: 0.5830\n",
      "Epoch 569/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7794 - accuracy: 0.7027 - val_loss: 1.2608 - val_accuracy: 0.5840\n",
      "Epoch 570/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7776 - accuracy: 0.7078 - val_loss: 1.2511 - val_accuracy: 0.5840\n",
      "Epoch 571/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7671 - accuracy: 0.7102 - val_loss: 1.2445 - val_accuracy: 0.5850\n",
      "Epoch 572/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7618 - accuracy: 0.7122 - val_loss: 1.2456 - val_accuracy: 0.5859\n",
      "Epoch 573/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7704 - accuracy: 0.7073 - val_loss: 1.2458 - val_accuracy: 0.5859\n",
      "Epoch 574/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7753 - accuracy: 0.7075 - val_loss: 1.2521 - val_accuracy: 0.5859\n",
      "Epoch 575/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7656 - accuracy: 0.7115 - val_loss: 1.2570 - val_accuracy: 0.5859\n",
      "Epoch 576/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7712 - accuracy: 0.7095 - val_loss: 1.2617 - val_accuracy: 0.5850\n",
      "Epoch 577/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7685 - accuracy: 0.7105 - val_loss: 1.2593 - val_accuracy: 0.5850\n",
      "Epoch 578/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7618 - accuracy: 0.7139 - val_loss: 1.2595 - val_accuracy: 0.5859\n",
      "Epoch 579/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7758 - accuracy: 0.7122 - val_loss: 1.2532 - val_accuracy: 0.5859\n",
      "Epoch 580/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7562 - accuracy: 0.7112 - val_loss: 1.2438 - val_accuracy: 0.5859\n",
      "Epoch 581/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7717 - accuracy: 0.7115 - val_loss: 1.2403 - val_accuracy: 0.5859\n",
      "Epoch 582/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7611 - accuracy: 0.7163 - val_loss: 1.2485 - val_accuracy: 0.5859\n",
      "Epoch 583/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7684 - accuracy: 0.7137 - val_loss: 1.2553 - val_accuracy: 0.5840\n",
      "Epoch 584/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7618 - accuracy: 0.7119 - val_loss: 1.2540 - val_accuracy: 0.5840\n",
      "Epoch 585/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7738 - accuracy: 0.7061 - val_loss: 1.2491 - val_accuracy: 0.5840\n",
      "Epoch 586/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7555 - accuracy: 0.7117 - val_loss: 1.2456 - val_accuracy: 0.5840\n",
      "Epoch 587/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7559 - accuracy: 0.7146 - val_loss: 1.2392 - val_accuracy: 0.5850\n",
      "Epoch 588/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7576 - accuracy: 0.7107 - val_loss: 1.2353 - val_accuracy: 0.5859\n",
      "Epoch 589/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7697 - accuracy: 0.7073 - val_loss: 1.2302 - val_accuracy: 0.5859\n",
      "Epoch 590/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7591 - accuracy: 0.7185 - val_loss: 1.2204 - val_accuracy: 0.5859\n",
      "Epoch 591/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7678 - accuracy: 0.7117 - val_loss: 1.2039 - val_accuracy: 0.5859\n",
      "Epoch 592/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7494 - accuracy: 0.7212 - val_loss: 1.1771 - val_accuracy: 0.5859\n",
      "Epoch 593/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7587 - accuracy: 0.7073 - val_loss: 1.1569 - val_accuracy: 0.5869\n",
      "Epoch 594/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7564 - accuracy: 0.7149 - val_loss: 1.1455 - val_accuracy: 0.5879\n",
      "Epoch 595/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7471 - accuracy: 0.7163 - val_loss: 1.1534 - val_accuracy: 0.5879\n",
      "Epoch 596/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7455 - accuracy: 0.7139 - val_loss: 1.1715 - val_accuracy: 0.5859\n",
      "Epoch 597/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7473 - accuracy: 0.7193 - val_loss: 1.1860 - val_accuracy: 0.5859\n",
      "Epoch 598/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7569 - accuracy: 0.7144 - val_loss: 1.2000 - val_accuracy: 0.5859\n",
      "Epoch 599/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7534 - accuracy: 0.7124 - val_loss: 1.2188 - val_accuracy: 0.5859\n",
      "Epoch 600/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7447 - accuracy: 0.7149 - val_loss: 1.2185 - val_accuracy: 0.5859\n",
      "Epoch 601/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7474 - accuracy: 0.7134 - val_loss: 1.2022 - val_accuracy: 0.5869\n",
      "Epoch 602/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7497 - accuracy: 0.7119 - val_loss: 1.1732 - val_accuracy: 0.5889\n",
      "Epoch 603/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7410 - accuracy: 0.7203 - val_loss: 1.1364 - val_accuracy: 0.5908\n",
      "Epoch 604/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7434 - accuracy: 0.7176 - val_loss: 1.1100 - val_accuracy: 0.5928\n",
      "Epoch 605/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7518 - accuracy: 0.7112 - val_loss: 1.1110 - val_accuracy: 0.5918\n",
      "Epoch 606/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7489 - accuracy: 0.7176 - val_loss: 1.1455 - val_accuracy: 0.5879\n",
      "Epoch 607/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7550 - accuracy: 0.7134 - val_loss: 1.1671 - val_accuracy: 0.5879\n",
      "Epoch 608/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7418 - accuracy: 0.7185 - val_loss: 1.1832 - val_accuracy: 0.5869\n",
      "Epoch 609/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7480 - accuracy: 0.7132 - val_loss: 1.1904 - val_accuracy: 0.5869\n",
      "Epoch 610/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7418 - accuracy: 0.7110 - val_loss: 1.1876 - val_accuracy: 0.5879\n",
      "Epoch 611/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7455 - accuracy: 0.7190 - val_loss: 1.1702 - val_accuracy: 0.5879\n",
      "Epoch 612/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7342 - accuracy: 0.7210 - val_loss: 1.1359 - val_accuracy: 0.5918\n",
      "Epoch 613/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7417 - accuracy: 0.7193 - val_loss: 1.0861 - val_accuracy: 0.5938\n",
      "Epoch 614/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7389 - accuracy: 0.7183 - val_loss: 1.0436 - val_accuracy: 0.5986\n",
      "Epoch 615/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7369 - accuracy: 0.7210 - val_loss: 1.0365 - val_accuracy: 0.5977\n",
      "Epoch 616/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7419 - accuracy: 0.7237 - val_loss: 1.0529 - val_accuracy: 0.5977\n",
      "Epoch 617/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7442 - accuracy: 0.7151 - val_loss: 1.1375 - val_accuracy: 0.5967\n",
      "Epoch 618/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7289 - accuracy: 0.7222 - val_loss: 1.1176 - val_accuracy: 0.5928\n",
      "Epoch 619/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7386 - accuracy: 0.7141 - val_loss: 1.1783 - val_accuracy: 0.5889\n",
      "Epoch 620/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7369 - accuracy: 0.7239 - val_loss: 1.2078 - val_accuracy: 0.5879\n",
      "Epoch 621/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7384 - accuracy: 0.7190 - val_loss: 1.2164 - val_accuracy: 0.5879\n",
      "Epoch 622/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7354 - accuracy: 0.7154 - val_loss: 1.2061 - val_accuracy: 0.5879\n",
      "Epoch 623/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7374 - accuracy: 0.7247 - val_loss: 1.1763 - val_accuracy: 0.5918\n",
      "Epoch 624/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7343 - accuracy: 0.7151 - val_loss: 1.1320 - val_accuracy: 0.5938\n",
      "Epoch 625/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7281 - accuracy: 0.7232 - val_loss: 1.0920 - val_accuracy: 0.5957\n",
      "Epoch 626/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7346 - accuracy: 0.7198 - val_loss: 1.0603 - val_accuracy: 0.5977\n",
      "Epoch 627/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7242 - accuracy: 0.7195 - val_loss: 1.0598 - val_accuracy: 0.5977\n",
      "Epoch 628/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7259 - accuracy: 0.7193 - val_loss: 1.0876 - val_accuracy: 0.5986\n",
      "Epoch 629/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7240 - accuracy: 0.7259 - val_loss: 1.0962 - val_accuracy: 0.5977\n",
      "Epoch 630/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7304 - accuracy: 0.7181 - val_loss: 1.1171 - val_accuracy: 0.5967\n",
      "Epoch 631/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7349 - accuracy: 0.7205 - val_loss: 1.1269 - val_accuracy: 0.5957\n",
      "Epoch 632/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7311 - accuracy: 0.7178 - val_loss: 1.1112 - val_accuracy: 0.5967\n",
      "Epoch 633/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7250 - accuracy: 0.7171 - val_loss: 1.0610 - val_accuracy: 0.6006\n",
      "Epoch 634/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7259 - accuracy: 0.7210 - val_loss: 0.9977 - val_accuracy: 0.6094\n",
      "Epoch 635/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7129 - accuracy: 0.7203 - val_loss: 0.9494 - val_accuracy: 0.6162\n",
      "Epoch 636/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7156 - accuracy: 0.7234 - val_loss: 0.9138 - val_accuracy: 0.6309\n",
      "Epoch 637/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7268 - accuracy: 0.7178 - val_loss: 0.8983 - val_accuracy: 0.6338\n",
      "Epoch 638/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7302 - accuracy: 0.7205 - val_loss: 0.8938 - val_accuracy: 0.6367\n",
      "Epoch 639/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7284 - accuracy: 0.7181 - val_loss: 0.9016 - val_accuracy: 0.6318\n",
      "Epoch 640/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7245 - accuracy: 0.7247 - val_loss: 0.9440 - val_accuracy: 0.6191\n",
      "Epoch 641/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7196 - accuracy: 0.7244 - val_loss: 1.0095 - val_accuracy: 0.6104\n",
      "Epoch 642/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7255 - accuracy: 0.7232 - val_loss: 1.0445 - val_accuracy: 0.6055\n",
      "Epoch 643/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7283 - accuracy: 0.7198 - val_loss: 1.0617 - val_accuracy: 0.6035\n",
      "Epoch 644/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7204 - accuracy: 0.7264 - val_loss: 1.0640 - val_accuracy: 0.6035\n",
      "Epoch 645/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7126 - accuracy: 0.7232 - val_loss: 1.0774 - val_accuracy: 0.6035\n",
      "Epoch 646/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7090 - accuracy: 0.7271 - val_loss: 1.0914 - val_accuracy: 0.6025\n",
      "Epoch 647/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7067 - accuracy: 0.7269 - val_loss: 1.0983 - val_accuracy: 0.6006\n",
      "Epoch 648/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7156 - accuracy: 0.7283 - val_loss: 1.0893 - val_accuracy: 0.6035\n",
      "Epoch 649/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7125 - accuracy: 0.7237 - val_loss: 1.0725 - val_accuracy: 0.6045\n",
      "Epoch 650/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7207 - accuracy: 0.7144 - val_loss: 1.0519 - val_accuracy: 0.6055\n",
      "Epoch 651/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7160 - accuracy: 0.7249 - val_loss: 1.0386 - val_accuracy: 0.6055\n",
      "Epoch 652/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7037 - accuracy: 0.7281 - val_loss: 1.0321 - val_accuracy: 0.6074\n",
      "Epoch 653/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7025 - accuracy: 0.7281 - val_loss: 1.0283 - val_accuracy: 0.6084\n",
      "Epoch 654/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7031 - accuracy: 0.7308 - val_loss: 1.0047 - val_accuracy: 0.6133\n",
      "Epoch 655/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7094 - accuracy: 0.7259 - val_loss: 0.9777 - val_accuracy: 0.6211\n",
      "Epoch 656/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7129 - accuracy: 0.7205 - val_loss: 0.9488 - val_accuracy: 0.6240\n",
      "Epoch 657/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7052 - accuracy: 0.7293 - val_loss: 0.9207 - val_accuracy: 0.6270\n",
      "Epoch 658/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7106 - accuracy: 0.7271 - val_loss: 0.9078 - val_accuracy: 0.6357\n",
      "Epoch 659/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7163 - accuracy: 0.7232 - val_loss: 0.8943 - val_accuracy: 0.6367\n",
      "Epoch 660/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7013 - accuracy: 0.7290 - val_loss: 0.8879 - val_accuracy: 0.6426\n",
      "Epoch 661/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6957 - accuracy: 0.7305 - val_loss: 0.8829 - val_accuracy: 0.6475\n",
      "Epoch 662/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7041 - accuracy: 0.7276 - val_loss: 0.8891 - val_accuracy: 0.6484\n",
      "Epoch 663/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7076 - accuracy: 0.7247 - val_loss: 0.8988 - val_accuracy: 0.6416\n",
      "Epoch 664/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6997 - accuracy: 0.7300 - val_loss: 0.9042 - val_accuracy: 0.6377\n",
      "Epoch 665/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6956 - accuracy: 0.7295 - val_loss: 0.9050 - val_accuracy: 0.6367\n",
      "Epoch 666/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6957 - accuracy: 0.7254 - val_loss: 0.8987 - val_accuracy: 0.6387\n",
      "Epoch 667/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6953 - accuracy: 0.7312 - val_loss: 0.8861 - val_accuracy: 0.6494\n",
      "Epoch 668/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6975 - accuracy: 0.7286 - val_loss: 0.8740 - val_accuracy: 0.6533\n",
      "Epoch 669/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6956 - accuracy: 0.7330 - val_loss: 0.8726 - val_accuracy: 0.6641\n",
      "Epoch 670/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6948 - accuracy: 0.7334 - val_loss: 0.8754 - val_accuracy: 0.6729\n",
      "Epoch 671/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6834 - accuracy: 0.7383 - val_loss: 0.8796 - val_accuracy: 0.6719\n",
      "Epoch 672/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6906 - accuracy: 0.7310 - val_loss: 0.8803 - val_accuracy: 0.6699\n",
      "Epoch 673/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6967 - accuracy: 0.7242 - val_loss: 0.8779 - val_accuracy: 0.6709\n",
      "Epoch 674/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6873 - accuracy: 0.7356 - val_loss: 0.8730 - val_accuracy: 0.6758\n",
      "Epoch 675/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6916 - accuracy: 0.7300 - val_loss: 0.8709 - val_accuracy: 0.6895\n",
      "Epoch 676/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6791 - accuracy: 0.7327 - val_loss: 0.8741 - val_accuracy: 0.6973\n",
      "Epoch 677/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7014 - accuracy: 0.7356 - val_loss: 0.8789 - val_accuracy: 0.7002\n",
      "Epoch 678/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6831 - accuracy: 0.7371 - val_loss: 0.8765 - val_accuracy: 0.6855\n",
      "Epoch 679/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6949 - accuracy: 0.7352 - val_loss: 0.8760 - val_accuracy: 0.6670\n",
      "Epoch 680/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6902 - accuracy: 0.7312 - val_loss: 0.8871 - val_accuracy: 0.6523\n",
      "Epoch 681/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6958 - accuracy: 0.7283 - val_loss: 0.8920 - val_accuracy: 0.6484\n",
      "Epoch 682/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6904 - accuracy: 0.7325 - val_loss: 0.8911 - val_accuracy: 0.6465\n",
      "Epoch 683/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6996 - accuracy: 0.7349 - val_loss: 0.8859 - val_accuracy: 0.6533\n",
      "Epoch 684/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6822 - accuracy: 0.7320 - val_loss: 0.8794 - val_accuracy: 0.6582\n",
      "Epoch 685/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6849 - accuracy: 0.7325 - val_loss: 0.8760 - val_accuracy: 0.6592\n",
      "Epoch 686/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6863 - accuracy: 0.7310 - val_loss: 0.8791 - val_accuracy: 0.6553\n",
      "Epoch 687/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6896 - accuracy: 0.7303 - val_loss: 0.8923 - val_accuracy: 0.6475\n",
      "Epoch 688/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6941 - accuracy: 0.7281 - val_loss: 0.9012 - val_accuracy: 0.6455\n",
      "Epoch 689/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6887 - accuracy: 0.7295 - val_loss: 0.9058 - val_accuracy: 0.6436\n",
      "Epoch 690/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6737 - accuracy: 0.7310 - val_loss: 0.9019 - val_accuracy: 0.6455\n",
      "Epoch 691/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6934 - accuracy: 0.7342 - val_loss: 0.8974 - val_accuracy: 0.6455\n",
      "Epoch 692/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6816 - accuracy: 0.7361 - val_loss: 0.8928 - val_accuracy: 0.6484\n",
      "Epoch 693/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6786 - accuracy: 0.7369 - val_loss: 0.8810 - val_accuracy: 0.6582\n",
      "Epoch 694/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6731 - accuracy: 0.7369 - val_loss: 0.8813 - val_accuracy: 0.6621\n",
      "Epoch 695/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6771 - accuracy: 0.7352 - val_loss: 0.8884 - val_accuracy: 0.6582\n",
      "Epoch 696/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6767 - accuracy: 0.7398 - val_loss: 0.8904 - val_accuracy: 0.6602\n",
      "Epoch 697/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6938 - accuracy: 0.7332 - val_loss: 0.8933 - val_accuracy: 0.6611\n",
      "Epoch 698/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6734 - accuracy: 0.7320 - val_loss: 0.8991 - val_accuracy: 0.6572\n",
      "Epoch 699/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6769 - accuracy: 0.7391 - val_loss: 0.9008 - val_accuracy: 0.6562\n",
      "Epoch 700/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6700 - accuracy: 0.7337 - val_loss: 0.9015 - val_accuracy: 0.6543\n",
      "Epoch 701/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6575 - accuracy: 0.7457 - val_loss: 0.8984 - val_accuracy: 0.6592\n",
      "Epoch 702/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6702 - accuracy: 0.7388 - val_loss: 0.8974 - val_accuracy: 0.6650\n",
      "Epoch 703/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6607 - accuracy: 0.7383 - val_loss: 0.8925 - val_accuracy: 0.6660\n",
      "Epoch 704/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6844 - accuracy: 0.7334 - val_loss: 0.8945 - val_accuracy: 0.6689\n",
      "Epoch 705/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6982 - accuracy: 0.7298 - val_loss: 0.9118 - val_accuracy: 0.6523\n",
      "Epoch 706/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6941 - accuracy: 0.7308 - val_loss: 0.9335 - val_accuracy: 0.6475\n",
      "Epoch 707/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6877 - accuracy: 0.7303 - val_loss: 0.9352 - val_accuracy: 0.6484\n",
      "Epoch 708/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7099 - accuracy: 0.7295 - val_loss: 0.9227 - val_accuracy: 0.6553\n",
      "Epoch 709/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7062 - accuracy: 0.7251 - val_loss: 0.9049 - val_accuracy: 0.6631\n",
      "Epoch 710/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7185 - accuracy: 0.7156 - val_loss: 0.8860 - val_accuracy: 0.6660\n",
      "Epoch 711/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7246 - accuracy: 0.7100 - val_loss: 0.8741 - val_accuracy: 0.6719\n",
      "Epoch 712/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7208 - accuracy: 0.7159 - val_loss: 0.8519 - val_accuracy: 0.6807\n",
      "Epoch 713/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7156 - accuracy: 0.7237 - val_loss: 0.8314 - val_accuracy: 0.6836\n",
      "Epoch 714/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7003 - accuracy: 0.7242 - val_loss: 0.8150 - val_accuracy: 0.6934\n",
      "Epoch 715/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7129 - accuracy: 0.7163 - val_loss: 0.8100 - val_accuracy: 0.6924\n",
      "Epoch 716/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7018 - accuracy: 0.7237 - val_loss: 0.8115 - val_accuracy: 0.6914\n",
      "Epoch 717/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7092 - accuracy: 0.7229 - val_loss: 0.8096 - val_accuracy: 0.6914\n",
      "Epoch 718/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7119 - accuracy: 0.7237 - val_loss: 0.8039 - val_accuracy: 0.6904\n",
      "Epoch 719/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7030 - accuracy: 0.7293 - val_loss: 0.7908 - val_accuracy: 0.6982\n",
      "Epoch 720/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6981 - accuracy: 0.7193 - val_loss: 0.7844 - val_accuracy: 0.6953\n",
      "Epoch 721/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6954 - accuracy: 0.7269 - val_loss: 0.8030 - val_accuracy: 0.6895\n",
      "Epoch 722/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7010 - accuracy: 0.7254 - val_loss: 0.8236 - val_accuracy: 0.6807\n",
      "Epoch 723/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6930 - accuracy: 0.7332 - val_loss: 0.8358 - val_accuracy: 0.6768\n",
      "Epoch 724/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6983 - accuracy: 0.7342 - val_loss: 0.8323 - val_accuracy: 0.6807\n",
      "Epoch 725/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6869 - accuracy: 0.7332 - val_loss: 0.8153 - val_accuracy: 0.6924\n",
      "Epoch 726/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6884 - accuracy: 0.7330 - val_loss: 0.7859 - val_accuracy: 0.6992\n",
      "Epoch 727/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6908 - accuracy: 0.7225 - val_loss: 0.7737 - val_accuracy: 0.7031\n",
      "Epoch 728/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6922 - accuracy: 0.7332 - val_loss: 0.7711 - val_accuracy: 0.7061\n",
      "Epoch 729/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6986 - accuracy: 0.7259 - val_loss: 0.7723 - val_accuracy: 0.7051\n",
      "Epoch 730/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6738 - accuracy: 0.7376 - val_loss: 0.7761 - val_accuracy: 0.7090\n",
      "Epoch 731/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6729 - accuracy: 0.7354 - val_loss: 0.7814 - val_accuracy: 0.7119\n",
      "Epoch 732/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6850 - accuracy: 0.7327 - val_loss: 0.7858 - val_accuracy: 0.7129\n",
      "Epoch 733/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6907 - accuracy: 0.7290 - val_loss: 0.7875 - val_accuracy: 0.7148\n",
      "Epoch 734/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6773 - accuracy: 0.7325 - val_loss: 0.7869 - val_accuracy: 0.7109\n",
      "Epoch 735/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6893 - accuracy: 0.7359 - val_loss: 0.7847 - val_accuracy: 0.7080\n",
      "Epoch 736/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6783 - accuracy: 0.7386 - val_loss: 0.7865 - val_accuracy: 0.7070\n",
      "Epoch 737/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6693 - accuracy: 0.7339 - val_loss: 0.7925 - val_accuracy: 0.7070\n",
      "Epoch 738/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6676 - accuracy: 0.7378 - val_loss: 0.7959 - val_accuracy: 0.7041\n",
      "Epoch 739/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6730 - accuracy: 0.7361 - val_loss: 0.7992 - val_accuracy: 0.7031\n",
      "Epoch 740/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6783 - accuracy: 0.7378 - val_loss: 0.7975 - val_accuracy: 0.7031\n",
      "Epoch 741/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6719 - accuracy: 0.7344 - val_loss: 0.7901 - val_accuracy: 0.7041\n",
      "Epoch 742/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6750 - accuracy: 0.7386 - val_loss: 0.7797 - val_accuracy: 0.7070\n",
      "Epoch 743/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6657 - accuracy: 0.7371 - val_loss: 0.7694 - val_accuracy: 0.7119\n",
      "Epoch 744/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6613 - accuracy: 0.7393 - val_loss: 0.7660 - val_accuracy: 0.7109\n",
      "Epoch 745/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6739 - accuracy: 0.7337 - val_loss: 0.7720 - val_accuracy: 0.7109\n",
      "Epoch 746/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6596 - accuracy: 0.7374 - val_loss: 0.7813 - val_accuracy: 0.7061\n",
      "Epoch 747/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6650 - accuracy: 0.7337 - val_loss: 0.7868 - val_accuracy: 0.7051\n",
      "Epoch 748/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6593 - accuracy: 0.7405 - val_loss: 0.7869 - val_accuracy: 0.7051\n",
      "Epoch 749/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6708 - accuracy: 0.7312 - val_loss: 0.7842 - val_accuracy: 0.7051\n",
      "Epoch 750/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6596 - accuracy: 0.7361 - val_loss: 0.7795 - val_accuracy: 0.7070\n",
      "Epoch 751/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6707 - accuracy: 0.7440 - val_loss: 0.7723 - val_accuracy: 0.7090\n",
      "Epoch 752/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6717 - accuracy: 0.7315 - val_loss: 0.7697 - val_accuracy: 0.7119\n",
      "Epoch 753/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6533 - accuracy: 0.7420 - val_loss: 0.7771 - val_accuracy: 0.7100\n",
      "Epoch 754/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6591 - accuracy: 0.7388 - val_loss: 0.7945 - val_accuracy: 0.7041\n",
      "Epoch 755/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6643 - accuracy: 0.7354 - val_loss: 0.8231 - val_accuracy: 0.6885\n",
      "Epoch 756/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6456 - accuracy: 0.7471 - val_loss: 0.8485 - val_accuracy: 0.6816\n",
      "Epoch 757/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6535 - accuracy: 0.7349 - val_loss: 0.8453 - val_accuracy: 0.6807\n",
      "Epoch 758/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6613 - accuracy: 0.7383 - val_loss: 0.8237 - val_accuracy: 0.6875\n",
      "Epoch 759/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6603 - accuracy: 0.7322 - val_loss: 0.8048 - val_accuracy: 0.6963\n",
      "Epoch 760/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6631 - accuracy: 0.7430 - val_loss: 0.7893 - val_accuracy: 0.7051\n",
      "Epoch 761/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6506 - accuracy: 0.7378 - val_loss: 0.7833 - val_accuracy: 0.7070\n",
      "Epoch 762/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6528 - accuracy: 0.7452 - val_loss: 0.7869 - val_accuracy: 0.7061\n",
      "Epoch 763/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6658 - accuracy: 0.7388 - val_loss: 0.7964 - val_accuracy: 0.7012\n",
      "Epoch 764/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6526 - accuracy: 0.7418 - val_loss: 0.8119 - val_accuracy: 0.6943\n",
      "Epoch 765/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6560 - accuracy: 0.7376 - val_loss: 0.8230 - val_accuracy: 0.6826\n",
      "Epoch 766/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6535 - accuracy: 0.7391 - val_loss: 0.8347 - val_accuracy: 0.6797\n",
      "Epoch 767/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6475 - accuracy: 0.7388 - val_loss: 0.8318 - val_accuracy: 0.6836\n",
      "Epoch 768/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6415 - accuracy: 0.7496 - val_loss: 0.8201 - val_accuracy: 0.6924\n",
      "Epoch 769/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6534 - accuracy: 0.7457 - val_loss: 0.8080 - val_accuracy: 0.6943\n",
      "Epoch 770/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6485 - accuracy: 0.7435 - val_loss: 0.7925 - val_accuracy: 0.7002\n",
      "Epoch 771/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6574 - accuracy: 0.7371 - val_loss: 0.7847 - val_accuracy: 0.7041\n",
      "Epoch 772/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6510 - accuracy: 0.7479 - val_loss: 0.7843 - val_accuracy: 0.7041\n",
      "Epoch 773/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6444 - accuracy: 0.7437 - val_loss: 0.7910 - val_accuracy: 0.7051\n",
      "Epoch 774/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6457 - accuracy: 0.7403 - val_loss: 0.8055 - val_accuracy: 0.6992\n",
      "Epoch 775/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6338 - accuracy: 0.7527 - val_loss: 0.8130 - val_accuracy: 0.6963\n",
      "Epoch 776/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6434 - accuracy: 0.7520 - val_loss: 0.8137 - val_accuracy: 0.6992\n",
      "Epoch 777/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6396 - accuracy: 0.7427 - val_loss: 0.8120 - val_accuracy: 0.7021\n",
      "Epoch 778/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6505 - accuracy: 0.7464 - val_loss: 0.8102 - val_accuracy: 0.7021\n",
      "Epoch 779/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6462 - accuracy: 0.7513 - val_loss: 0.8072 - val_accuracy: 0.7002\n",
      "Epoch 780/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6427 - accuracy: 0.7479 - val_loss: 0.8005 - val_accuracy: 0.7002\n",
      "Epoch 781/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6284 - accuracy: 0.7496 - val_loss: 0.7960 - val_accuracy: 0.7061\n",
      "Epoch 782/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6315 - accuracy: 0.7474 - val_loss: 0.7969 - val_accuracy: 0.7061\n",
      "Epoch 783/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6428 - accuracy: 0.7425 - val_loss: 0.7984 - val_accuracy: 0.7031\n",
      "Epoch 784/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6308 - accuracy: 0.7508 - val_loss: 0.7963 - val_accuracy: 0.7041\n",
      "Epoch 785/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6401 - accuracy: 0.7466 - val_loss: 0.7910 - val_accuracy: 0.7051\n",
      "Epoch 786/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6435 - accuracy: 0.7391 - val_loss: 0.7860 - val_accuracy: 0.7041\n",
      "Epoch 787/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6334 - accuracy: 0.7584 - val_loss: 0.7812 - val_accuracy: 0.7041\n",
      "Epoch 788/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6365 - accuracy: 0.7513 - val_loss: 0.7800 - val_accuracy: 0.7051\n",
      "Epoch 789/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6357 - accuracy: 0.7520 - val_loss: 0.7836 - val_accuracy: 0.7002\n",
      "Epoch 790/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6265 - accuracy: 0.7488 - val_loss: 0.7879 - val_accuracy: 0.6992\n",
      "Epoch 791/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6329 - accuracy: 0.7591 - val_loss: 0.7978 - val_accuracy: 0.6943\n",
      "Epoch 792/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6314 - accuracy: 0.7540 - val_loss: 0.8060 - val_accuracy: 0.6934\n",
      "Epoch 793/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6323 - accuracy: 0.7508 - val_loss: 0.8033 - val_accuracy: 0.6963\n",
      "Epoch 794/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6360 - accuracy: 0.7486 - val_loss: 0.7964 - val_accuracy: 0.6963\n",
      "Epoch 795/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6309 - accuracy: 0.7540 - val_loss: 0.7767 - val_accuracy: 0.7031\n",
      "Epoch 796/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6294 - accuracy: 0.7493 - val_loss: 0.7771 - val_accuracy: 0.7031\n",
      "Epoch 797/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6150 - accuracy: 0.7557 - val_loss: 0.7909 - val_accuracy: 0.7002\n",
      "Epoch 798/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6259 - accuracy: 0.7547 - val_loss: 0.8101 - val_accuracy: 0.6943\n",
      "Epoch 799/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6173 - accuracy: 0.7576 - val_loss: 0.8250 - val_accuracy: 0.6914\n",
      "Epoch 800/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6321 - accuracy: 0.7496 - val_loss: 0.8221 - val_accuracy: 0.6963\n",
      "Epoch 801/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6292 - accuracy: 0.7615 - val_loss: 0.8134 - val_accuracy: 0.6992\n",
      "Epoch 802/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6244 - accuracy: 0.7549 - val_loss: 0.8075 - val_accuracy: 0.7031\n",
      "Epoch 803/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6232 - accuracy: 0.7567 - val_loss: 0.8074 - val_accuracy: 0.7100\n",
      "Epoch 804/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6350 - accuracy: 0.7488 - val_loss: 0.8088 - val_accuracy: 0.7178\n",
      "Epoch 805/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6287 - accuracy: 0.7540 - val_loss: 0.8159 - val_accuracy: 0.7168\n",
      "Epoch 806/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6183 - accuracy: 0.7552 - val_loss: 0.8192 - val_accuracy: 0.7129\n",
      "Epoch 807/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6207 - accuracy: 0.7584 - val_loss: 0.8208 - val_accuracy: 0.7217\n",
      "Epoch 808/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6494 - accuracy: 0.7374 - val_loss: 0.8421 - val_accuracy: 0.7021\n",
      "Epoch 809/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6691 - accuracy: 0.7303 - val_loss: 0.8292 - val_accuracy: 0.7080\n",
      "Epoch 810/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6483 - accuracy: 0.7420 - val_loss: 0.8163 - val_accuracy: 0.7041\n",
      "Epoch 811/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6724 - accuracy: 0.7290 - val_loss: 0.7925 - val_accuracy: 0.7080\n",
      "Epoch 812/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6527 - accuracy: 0.7369 - val_loss: 0.8148 - val_accuracy: 0.6943\n",
      "Epoch 813/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6613 - accuracy: 0.7378 - val_loss: 0.8763 - val_accuracy: 0.6846\n",
      "Epoch 814/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6768 - accuracy: 0.7325 - val_loss: 0.9208 - val_accuracy: 0.6758\n",
      "Epoch 815/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6722 - accuracy: 0.7405 - val_loss: 0.9332 - val_accuracy: 0.6611\n",
      "Epoch 816/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6724 - accuracy: 0.7349 - val_loss: 0.9118 - val_accuracy: 0.6621\n",
      "Epoch 817/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6659 - accuracy: 0.7440 - val_loss: 0.8741 - val_accuracy: 0.6758\n",
      "Epoch 818/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6610 - accuracy: 0.7418 - val_loss: 0.8293 - val_accuracy: 0.6924\n",
      "Epoch 819/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6805 - accuracy: 0.7349 - val_loss: 0.8031 - val_accuracy: 0.7012\n",
      "Epoch 820/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6776 - accuracy: 0.7359 - val_loss: 0.7848 - val_accuracy: 0.7090\n",
      "Epoch 821/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6585 - accuracy: 0.7391 - val_loss: 0.7756 - val_accuracy: 0.7119\n",
      "Epoch 822/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6639 - accuracy: 0.7440 - val_loss: 0.7693 - val_accuracy: 0.7119\n",
      "Epoch 823/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6586 - accuracy: 0.7359 - val_loss: 0.7642 - val_accuracy: 0.7139\n",
      "Epoch 824/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6585 - accuracy: 0.7471 - val_loss: 0.7657 - val_accuracy: 0.7100\n",
      "Epoch 825/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6480 - accuracy: 0.7442 - val_loss: 0.7739 - val_accuracy: 0.7100\n",
      "Epoch 826/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6506 - accuracy: 0.7466 - val_loss: 0.7803 - val_accuracy: 0.7061\n",
      "Epoch 827/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6481 - accuracy: 0.7491 - val_loss: 0.7820 - val_accuracy: 0.6992\n",
      "Epoch 828/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6424 - accuracy: 0.7518 - val_loss: 0.7776 - val_accuracy: 0.7002\n",
      "Epoch 829/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6460 - accuracy: 0.7422 - val_loss: 0.7691 - val_accuracy: 0.7021\n",
      "Epoch 830/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6370 - accuracy: 0.7515 - val_loss: 0.7640 - val_accuracy: 0.7041\n",
      "Epoch 831/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6451 - accuracy: 0.7469 - val_loss: 0.7624 - val_accuracy: 0.7041\n",
      "Epoch 832/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6361 - accuracy: 0.7466 - val_loss: 0.7565 - val_accuracy: 0.7080\n",
      "Epoch 833/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6536 - accuracy: 0.7484 - val_loss: 0.7439 - val_accuracy: 0.7109\n",
      "Epoch 834/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6362 - accuracy: 0.7542 - val_loss: 0.7396 - val_accuracy: 0.7090\n",
      "Epoch 835/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6294 - accuracy: 0.7452 - val_loss: 0.7386 - val_accuracy: 0.7090\n",
      "Epoch 836/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6363 - accuracy: 0.7454 - val_loss: 0.7368 - val_accuracy: 0.7100\n",
      "Epoch 837/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6387 - accuracy: 0.7386 - val_loss: 0.7447 - val_accuracy: 0.7119\n",
      "Epoch 838/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6482 - accuracy: 0.7488 - val_loss: 0.7645 - val_accuracy: 0.7031\n",
      "Epoch 839/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6315 - accuracy: 0.7591 - val_loss: 0.7897 - val_accuracy: 0.6982\n",
      "Epoch 840/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6506 - accuracy: 0.7515 - val_loss: 0.8089 - val_accuracy: 0.6963\n",
      "Epoch 841/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6414 - accuracy: 0.7537 - val_loss: 0.8190 - val_accuracy: 0.6924\n",
      "Epoch 842/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6207 - accuracy: 0.7571 - val_loss: 0.8073 - val_accuracy: 0.6982\n",
      "Epoch 843/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6419 - accuracy: 0.7540 - val_loss: 0.7909 - val_accuracy: 0.6992\n",
      "Epoch 844/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6414 - accuracy: 0.7549 - val_loss: 0.7733 - val_accuracy: 0.7002\n",
      "Epoch 845/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6386 - accuracy: 0.7532 - val_loss: 0.7529 - val_accuracy: 0.7070\n",
      "Epoch 846/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6363 - accuracy: 0.7549 - val_loss: 0.7323 - val_accuracy: 0.7119\n",
      "Epoch 847/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6343 - accuracy: 0.7532 - val_loss: 0.7218 - val_accuracy: 0.7158\n",
      "Epoch 848/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6261 - accuracy: 0.7493 - val_loss: 0.7163 - val_accuracy: 0.7188\n",
      "Epoch 849/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6144 - accuracy: 0.7584 - val_loss: 0.7193 - val_accuracy: 0.7148\n",
      "Epoch 850/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6225 - accuracy: 0.7493 - val_loss: 0.7240 - val_accuracy: 0.7158\n",
      "Epoch 851/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6283 - accuracy: 0.7547 - val_loss: 0.7254 - val_accuracy: 0.7148\n",
      "Epoch 852/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6258 - accuracy: 0.7586 - val_loss: 0.7274 - val_accuracy: 0.7109\n",
      "Epoch 853/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6286 - accuracy: 0.7584 - val_loss: 0.7347 - val_accuracy: 0.7129\n",
      "Epoch 854/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6384 - accuracy: 0.7491 - val_loss: 0.7415 - val_accuracy: 0.7090\n",
      "Epoch 855/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6157 - accuracy: 0.7603 - val_loss: 0.7371 - val_accuracy: 0.7109\n",
      "Epoch 856/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6206 - accuracy: 0.7630 - val_loss: 0.7335 - val_accuracy: 0.7139\n",
      "Epoch 857/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6074 - accuracy: 0.7606 - val_loss: 0.7316 - val_accuracy: 0.7168\n",
      "Epoch 858/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6151 - accuracy: 0.7628 - val_loss: 0.7283 - val_accuracy: 0.7178\n",
      "Epoch 859/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6073 - accuracy: 0.7630 - val_loss: 0.7246 - val_accuracy: 0.7236\n",
      "Epoch 860/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6174 - accuracy: 0.7620 - val_loss: 0.7240 - val_accuracy: 0.7227\n",
      "Epoch 861/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6273 - accuracy: 0.7537 - val_loss: 0.7240 - val_accuracy: 0.7236\n",
      "Epoch 862/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6189 - accuracy: 0.7642 - val_loss: 0.7246 - val_accuracy: 0.7236\n",
      "Epoch 863/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6089 - accuracy: 0.7635 - val_loss: 0.7265 - val_accuracy: 0.7197\n",
      "Epoch 864/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6319 - accuracy: 0.7584 - val_loss: 0.7294 - val_accuracy: 0.7129\n",
      "Epoch 865/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6140 - accuracy: 0.7611 - val_loss: 0.7298 - val_accuracy: 0.7100\n",
      "Epoch 866/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6221 - accuracy: 0.7557 - val_loss: 0.7308 - val_accuracy: 0.7119\n",
      "Epoch 867/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6222 - accuracy: 0.7642 - val_loss: 0.7280 - val_accuracy: 0.7080\n",
      "Epoch 868/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6065 - accuracy: 0.7569 - val_loss: 0.7233 - val_accuracy: 0.7109\n",
      "Epoch 869/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6080 - accuracy: 0.7628 - val_loss: 0.7199 - val_accuracy: 0.7100\n",
      "Epoch 870/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6185 - accuracy: 0.7542 - val_loss: 0.7179 - val_accuracy: 0.7109\n",
      "Epoch 871/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6047 - accuracy: 0.7655 - val_loss: 0.7198 - val_accuracy: 0.7129\n",
      "Epoch 872/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6066 - accuracy: 0.7645 - val_loss: 0.7214 - val_accuracy: 0.7158\n",
      "Epoch 873/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6048 - accuracy: 0.7708 - val_loss: 0.7256 - val_accuracy: 0.7148\n",
      "Epoch 874/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6137 - accuracy: 0.7640 - val_loss: 0.7277 - val_accuracy: 0.7129\n",
      "Epoch 875/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6034 - accuracy: 0.7757 - val_loss: 0.7307 - val_accuracy: 0.7158\n",
      "Epoch 876/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5959 - accuracy: 0.7664 - val_loss: 0.7331 - val_accuracy: 0.7197\n",
      "Epoch 877/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6005 - accuracy: 0.7655 - val_loss: 0.7347 - val_accuracy: 0.7236\n",
      "Epoch 878/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6087 - accuracy: 0.7652 - val_loss: 0.7325 - val_accuracy: 0.7236\n",
      "Epoch 879/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6052 - accuracy: 0.7657 - val_loss: 0.7292 - val_accuracy: 0.7227\n",
      "Epoch 880/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5920 - accuracy: 0.7652 - val_loss: 0.7310 - val_accuracy: 0.7188\n",
      "Epoch 881/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6075 - accuracy: 0.7574 - val_loss: 0.7402 - val_accuracy: 0.7129\n",
      "Epoch 882/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6035 - accuracy: 0.7725 - val_loss: 0.7524 - val_accuracy: 0.7090\n",
      "Epoch 883/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6025 - accuracy: 0.7657 - val_loss: 0.7737 - val_accuracy: 0.7051\n",
      "Epoch 884/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5984 - accuracy: 0.7674 - val_loss: 0.7879 - val_accuracy: 0.7041\n",
      "Epoch 885/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5959 - accuracy: 0.7720 - val_loss: 0.7886 - val_accuracy: 0.7031\n",
      "Epoch 886/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6018 - accuracy: 0.7735 - val_loss: 0.7856 - val_accuracy: 0.7041\n",
      "Epoch 887/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6006 - accuracy: 0.7662 - val_loss: 0.7777 - val_accuracy: 0.7012\n",
      "Epoch 888/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6026 - accuracy: 0.7677 - val_loss: 0.7561 - val_accuracy: 0.7031\n",
      "Epoch 889/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6037 - accuracy: 0.7664 - val_loss: 0.7390 - val_accuracy: 0.7051\n",
      "Epoch 890/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5908 - accuracy: 0.7740 - val_loss: 0.7212 - val_accuracy: 0.7080\n",
      "Epoch 891/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5929 - accuracy: 0.7774 - val_loss: 0.7051 - val_accuracy: 0.7139\n",
      "Epoch 892/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6016 - accuracy: 0.7637 - val_loss: 0.7009 - val_accuracy: 0.7148\n",
      "Epoch 893/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5905 - accuracy: 0.7684 - val_loss: 0.7015 - val_accuracy: 0.7139\n",
      "Epoch 894/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5825 - accuracy: 0.7718 - val_loss: 0.7045 - val_accuracy: 0.7129\n",
      "Epoch 895/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5894 - accuracy: 0.7701 - val_loss: 0.7078 - val_accuracy: 0.7139\n",
      "Epoch 896/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5939 - accuracy: 0.7725 - val_loss: 0.7122 - val_accuracy: 0.7158\n",
      "Epoch 897/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5909 - accuracy: 0.7699 - val_loss: 0.7199 - val_accuracy: 0.7129\n",
      "Epoch 898/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5769 - accuracy: 0.7782 - val_loss: 0.7249 - val_accuracy: 0.7148\n",
      "Epoch 899/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5789 - accuracy: 0.7728 - val_loss: 0.7292 - val_accuracy: 0.7158\n",
      "Epoch 900/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6055 - accuracy: 0.7647 - val_loss: 0.7271 - val_accuracy: 0.7168\n",
      "Epoch 901/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5865 - accuracy: 0.7716 - val_loss: 0.7241 - val_accuracy: 0.7207\n",
      "Epoch 902/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5912 - accuracy: 0.7755 - val_loss: 0.7185 - val_accuracy: 0.7295\n",
      "Epoch 903/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5749 - accuracy: 0.7720 - val_loss: 0.7162 - val_accuracy: 0.7227\n",
      "Epoch 904/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5875 - accuracy: 0.7716 - val_loss: 0.7173 - val_accuracy: 0.7266\n",
      "Epoch 905/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5920 - accuracy: 0.7730 - val_loss: 0.7231 - val_accuracy: 0.7178\n",
      "Epoch 906/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5742 - accuracy: 0.7728 - val_loss: 0.7282 - val_accuracy: 0.7197\n",
      "Epoch 907/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5929 - accuracy: 0.7684 - val_loss: 0.7245 - val_accuracy: 0.7197\n",
      "Epoch 908/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5740 - accuracy: 0.7738 - val_loss: 0.7105 - val_accuracy: 0.7227\n",
      "Epoch 909/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5704 - accuracy: 0.7801 - val_loss: 0.7061 - val_accuracy: 0.7285\n",
      "Epoch 910/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5813 - accuracy: 0.7745 - val_loss: 0.7086 - val_accuracy: 0.7285\n",
      "Epoch 911/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5749 - accuracy: 0.7845 - val_loss: 0.7164 - val_accuracy: 0.7217\n",
      "Epoch 912/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5692 - accuracy: 0.7769 - val_loss: 0.7256 - val_accuracy: 0.7236\n",
      "Epoch 913/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5745 - accuracy: 0.7755 - val_loss: 0.7204 - val_accuracy: 0.7236\n",
      "Epoch 914/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5929 - accuracy: 0.7760 - val_loss: 0.7127 - val_accuracy: 0.7227\n",
      "Epoch 915/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5858 - accuracy: 0.7774 - val_loss: 0.7212 - val_accuracy: 0.7188\n",
      "Epoch 916/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5855 - accuracy: 0.7720 - val_loss: 0.7364 - val_accuracy: 0.7148\n",
      "Epoch 917/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5763 - accuracy: 0.7877 - val_loss: 0.7507 - val_accuracy: 0.7061\n",
      "Epoch 918/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5980 - accuracy: 0.7647 - val_loss: 0.7572 - val_accuracy: 0.7080\n",
      "Epoch 919/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5761 - accuracy: 0.7801 - val_loss: 0.7539 - val_accuracy: 0.7109\n",
      "Epoch 920/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5690 - accuracy: 0.7892 - val_loss: 0.7343 - val_accuracy: 0.7168\n",
      "Epoch 921/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5753 - accuracy: 0.7762 - val_loss: 0.7228 - val_accuracy: 0.7178\n",
      "Epoch 922/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5716 - accuracy: 0.7806 - val_loss: 0.7282 - val_accuracy: 0.7197\n",
      "Epoch 923/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5753 - accuracy: 0.7747 - val_loss: 0.7252 - val_accuracy: 0.7207\n",
      "Epoch 924/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5801 - accuracy: 0.7794 - val_loss: 0.7198 - val_accuracy: 0.7236\n",
      "Epoch 925/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5699 - accuracy: 0.7782 - val_loss: 0.7139 - val_accuracy: 0.7227\n",
      "Epoch 926/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5842 - accuracy: 0.7818 - val_loss: 0.7028 - val_accuracy: 0.7236\n",
      "Epoch 927/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5743 - accuracy: 0.7813 - val_loss: 0.7048 - val_accuracy: 0.7236\n",
      "Epoch 928/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5663 - accuracy: 0.7767 - val_loss: 0.7132 - val_accuracy: 0.7207\n",
      "Epoch 929/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5611 - accuracy: 0.7899 - val_loss: 0.7226 - val_accuracy: 0.7148\n",
      "Epoch 930/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5755 - accuracy: 0.7804 - val_loss: 0.7259 - val_accuracy: 0.7139\n",
      "Epoch 931/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5865 - accuracy: 0.7779 - val_loss: 0.7252 - val_accuracy: 0.7129\n",
      "Epoch 932/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5734 - accuracy: 0.7892 - val_loss: 0.7149 - val_accuracy: 0.7217\n",
      "Epoch 933/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5654 - accuracy: 0.7808 - val_loss: 0.7211 - val_accuracy: 0.7236\n",
      "Epoch 934/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5766 - accuracy: 0.7806 - val_loss: 0.7321 - val_accuracy: 0.7246\n",
      "Epoch 935/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5629 - accuracy: 0.7808 - val_loss: 0.7290 - val_accuracy: 0.7295\n",
      "Epoch 936/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5589 - accuracy: 0.7865 - val_loss: 0.7199 - val_accuracy: 0.7256\n",
      "Epoch 937/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5719 - accuracy: 0.7835 - val_loss: 0.7131 - val_accuracy: 0.7305\n",
      "Epoch 938/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5669 - accuracy: 0.7806 - val_loss: 0.7146 - val_accuracy: 0.7324\n",
      "Epoch 939/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5555 - accuracy: 0.7848 - val_loss: 0.7272 - val_accuracy: 0.7236\n",
      "Epoch 940/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5754 - accuracy: 0.7801 - val_loss: 0.7254 - val_accuracy: 0.7246\n",
      "Epoch 941/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5685 - accuracy: 0.7840 - val_loss: 0.7209 - val_accuracy: 0.7188\n",
      "Epoch 942/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5704 - accuracy: 0.7730 - val_loss: 0.7202 - val_accuracy: 0.7188\n",
      "Epoch 943/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5631 - accuracy: 0.7860 - val_loss: 0.7212 - val_accuracy: 0.7188\n",
      "Epoch 944/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5745 - accuracy: 0.7767 - val_loss: 0.7190 - val_accuracy: 0.7158\n",
      "Epoch 945/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5606 - accuracy: 0.7928 - val_loss: 0.7197 - val_accuracy: 0.7158\n",
      "Epoch 946/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5732 - accuracy: 0.7867 - val_loss: 0.7168 - val_accuracy: 0.7158\n",
      "Epoch 947/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5705 - accuracy: 0.7757 - val_loss: 0.7142 - val_accuracy: 0.7158\n",
      "Epoch 948/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5630 - accuracy: 0.7845 - val_loss: 0.7051 - val_accuracy: 0.7148\n",
      "Epoch 949/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5643 - accuracy: 0.7835 - val_loss: 0.7018 - val_accuracy: 0.7217\n",
      "Epoch 950/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5559 - accuracy: 0.7904 - val_loss: 0.7026 - val_accuracy: 0.7246\n",
      "Epoch 951/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5671 - accuracy: 0.7860 - val_loss: 0.7061 - val_accuracy: 0.7266\n",
      "Epoch 952/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5619 - accuracy: 0.7777 - val_loss: 0.7146 - val_accuracy: 0.7236\n",
      "Epoch 953/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5589 - accuracy: 0.7840 - val_loss: 0.7134 - val_accuracy: 0.7188\n",
      "Epoch 954/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5694 - accuracy: 0.7867 - val_loss: 0.7108 - val_accuracy: 0.7168\n",
      "Epoch 955/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5430 - accuracy: 0.7960 - val_loss: 0.7102 - val_accuracy: 0.7168\n",
      "Epoch 956/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5754 - accuracy: 0.7852 - val_loss: 0.7095 - val_accuracy: 0.7139\n",
      "Epoch 957/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5483 - accuracy: 0.7931 - val_loss: 0.7095 - val_accuracy: 0.7178\n",
      "Epoch 958/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5577 - accuracy: 0.7840 - val_loss: 0.7070 - val_accuracy: 0.7246\n",
      "Epoch 959/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5561 - accuracy: 0.7948 - val_loss: 0.7045 - val_accuracy: 0.7217\n",
      "Epoch 960/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5574 - accuracy: 0.7816 - val_loss: 0.7011 - val_accuracy: 0.7266\n",
      "Epoch 961/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5421 - accuracy: 0.7892 - val_loss: 0.6965 - val_accuracy: 0.7227\n",
      "Epoch 962/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5514 - accuracy: 0.7931 - val_loss: 0.6958 - val_accuracy: 0.7207\n",
      "Epoch 963/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5447 - accuracy: 0.7914 - val_loss: 0.6988 - val_accuracy: 0.7197\n",
      "Epoch 964/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5467 - accuracy: 0.7997 - val_loss: 0.7006 - val_accuracy: 0.7197\n",
      "Epoch 965/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5516 - accuracy: 0.7887 - val_loss: 0.7034 - val_accuracy: 0.7236\n",
      "Epoch 966/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5519 - accuracy: 0.7828 - val_loss: 0.7017 - val_accuracy: 0.7285\n",
      "Epoch 967/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5449 - accuracy: 0.7894 - val_loss: 0.6985 - val_accuracy: 0.7275\n",
      "Epoch 968/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5514 - accuracy: 0.7926 - val_loss: 0.6927 - val_accuracy: 0.7285\n",
      "Epoch 969/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5516 - accuracy: 0.7865 - val_loss: 0.6944 - val_accuracy: 0.7324\n",
      "Epoch 970/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5576 - accuracy: 0.7850 - val_loss: 0.7119 - val_accuracy: 0.7295\n",
      "Epoch 971/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5529 - accuracy: 0.7865 - val_loss: 0.7422 - val_accuracy: 0.7256\n",
      "Epoch 972/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5493 - accuracy: 0.7896 - val_loss: 0.7652 - val_accuracy: 0.7158\n",
      "Epoch 973/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5443 - accuracy: 0.7877 - val_loss: 0.7843 - val_accuracy: 0.6895\n",
      "Epoch 974/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5510 - accuracy: 0.7882 - val_loss: 0.7542 - val_accuracy: 0.7061\n",
      "Epoch 975/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5524 - accuracy: 0.7957 - val_loss: 0.7127 - val_accuracy: 0.7285\n",
      "Epoch 976/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5526 - accuracy: 0.7872 - val_loss: 0.6997 - val_accuracy: 0.7285\n",
      "Epoch 977/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5525 - accuracy: 0.7914 - val_loss: 0.7035 - val_accuracy: 0.7207\n",
      "Epoch 978/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5483 - accuracy: 0.7894 - val_loss: 0.7111 - val_accuracy: 0.7168\n",
      "Epoch 979/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5484 - accuracy: 0.7948 - val_loss: 0.7190 - val_accuracy: 0.7109\n",
      "Epoch 980/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5477 - accuracy: 0.7955 - val_loss: 0.7188 - val_accuracy: 0.7119\n",
      "Epoch 981/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5191 - accuracy: 0.8033 - val_loss: 0.7173 - val_accuracy: 0.7168\n",
      "Epoch 982/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5450 - accuracy: 0.7962 - val_loss: 0.7121 - val_accuracy: 0.7227\n",
      "Epoch 983/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5486 - accuracy: 0.7962 - val_loss: 0.7130 - val_accuracy: 0.7266\n",
      "Epoch 984/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5317 - accuracy: 0.7982 - val_loss: 0.7113 - val_accuracy: 0.7295\n",
      "Epoch 985/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5436 - accuracy: 0.7940 - val_loss: 0.6968 - val_accuracy: 0.7324\n",
      "Epoch 986/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5392 - accuracy: 0.7953 - val_loss: 0.6900 - val_accuracy: 0.7314\n",
      "Epoch 987/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5379 - accuracy: 0.7960 - val_loss: 0.6918 - val_accuracy: 0.7324\n",
      "Epoch 988/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5293 - accuracy: 0.8014 - val_loss: 0.6954 - val_accuracy: 0.7236\n",
      "Epoch 989/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5389 - accuracy: 0.7972 - val_loss: 0.6952 - val_accuracy: 0.7266\n",
      "Epoch 990/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5499 - accuracy: 0.7943 - val_loss: 0.6928 - val_accuracy: 0.7256\n",
      "Epoch 991/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5474 - accuracy: 0.7943 - val_loss: 0.6906 - val_accuracy: 0.7256\n",
      "Epoch 992/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5297 - accuracy: 0.7975 - val_loss: 0.7001 - val_accuracy: 0.7295\n",
      "Epoch 993/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5441 - accuracy: 0.7948 - val_loss: 0.7138 - val_accuracy: 0.7461\n",
      "Epoch 994/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5420 - accuracy: 0.7926 - val_loss: 0.7389 - val_accuracy: 0.7100\n",
      "Epoch 995/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5297 - accuracy: 0.7989 - val_loss: 0.7870 - val_accuracy: 0.6807\n",
      "Epoch 996/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5395 - accuracy: 0.7982 - val_loss: 0.7979 - val_accuracy: 0.6709\n",
      "Epoch 997/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5375 - accuracy: 0.7953 - val_loss: 0.7819 - val_accuracy: 0.6816\n",
      "Epoch 998/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5450 - accuracy: 0.7982 - val_loss: 0.7215 - val_accuracy: 0.7148\n",
      "Epoch 999/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5460 - accuracy: 0.7938 - val_loss: 0.6875 - val_accuracy: 0.7441\n",
      "Epoch 1000/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5490 - accuracy: 0.7899 - val_loss: 0.6834 - val_accuracy: 0.7334\n",
      "Epoch 1001/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5357 - accuracy: 0.7945 - val_loss: 0.6920 - val_accuracy: 0.7256\n",
      "Epoch 1002/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5409 - accuracy: 0.7975 - val_loss: 0.6992 - val_accuracy: 0.7217\n",
      "Epoch 1003/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5395 - accuracy: 0.7945 - val_loss: 0.7188 - val_accuracy: 0.7129\n",
      "Epoch 1004/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5232 - accuracy: 0.7989 - val_loss: 0.7219 - val_accuracy: 0.7139\n",
      "Epoch 1005/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5398 - accuracy: 0.7955 - val_loss: 0.7130 - val_accuracy: 0.7178\n",
      "Epoch 1006/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5330 - accuracy: 0.8038 - val_loss: 0.7279 - val_accuracy: 0.7139\n",
      "Epoch 1007/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5752 - accuracy: 0.7838 - val_loss: 0.7623 - val_accuracy: 0.7168\n",
      "Epoch 1008/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5871 - accuracy: 0.7708 - val_loss: 0.7348 - val_accuracy: 0.7373\n",
      "Epoch 1009/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5759 - accuracy: 0.7784 - val_loss: 0.7088 - val_accuracy: 0.7295\n",
      "Epoch 1010/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6023 - accuracy: 0.7581 - val_loss: 0.7195 - val_accuracy: 0.7119\n",
      "Epoch 1011/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6222 - accuracy: 0.7657 - val_loss: 0.7853 - val_accuracy: 0.6973\n",
      "Epoch 1012/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5966 - accuracy: 0.7716 - val_loss: 0.8363 - val_accuracy: 0.6885\n",
      "Epoch 1013/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6189 - accuracy: 0.7630 - val_loss: 0.8481 - val_accuracy: 0.6904\n",
      "Epoch 1014/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6106 - accuracy: 0.7672 - val_loss: 0.8266 - val_accuracy: 0.6934\n",
      "Epoch 1015/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6039 - accuracy: 0.7691 - val_loss: 0.7865 - val_accuracy: 0.6973\n",
      "Epoch 1016/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5737 - accuracy: 0.7782 - val_loss: 0.7517 - val_accuracy: 0.7021\n",
      "Epoch 1017/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6002 - accuracy: 0.7706 - val_loss: 0.7188 - val_accuracy: 0.7080\n",
      "Epoch 1018/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5823 - accuracy: 0.7764 - val_loss: 0.7074 - val_accuracy: 0.7207\n",
      "Epoch 1019/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5855 - accuracy: 0.7716 - val_loss: 0.7241 - val_accuracy: 0.7119\n",
      "Epoch 1020/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5953 - accuracy: 0.7674 - val_loss: 0.7676 - val_accuracy: 0.7139\n",
      "Epoch 1021/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5725 - accuracy: 0.7777 - val_loss: 0.7900 - val_accuracy: 0.7002\n",
      "Epoch 1022/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5734 - accuracy: 0.7757 - val_loss: 0.7671 - val_accuracy: 0.7021\n",
      "Epoch 1023/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5788 - accuracy: 0.7784 - val_loss: 0.7339 - val_accuracy: 0.7188\n",
      "Epoch 1024/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5673 - accuracy: 0.7801 - val_loss: 0.6984 - val_accuracy: 0.7305\n",
      "Epoch 1025/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5767 - accuracy: 0.7752 - val_loss: 0.6870 - val_accuracy: 0.7354\n",
      "Epoch 1026/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5647 - accuracy: 0.7899 - val_loss: 0.6906 - val_accuracy: 0.7324\n",
      "Epoch 1027/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5634 - accuracy: 0.7887 - val_loss: 0.7020 - val_accuracy: 0.7266\n",
      "Epoch 1028/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5662 - accuracy: 0.7906 - val_loss: 0.7106 - val_accuracy: 0.7236\n",
      "Epoch 1029/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5667 - accuracy: 0.7845 - val_loss: 0.7131 - val_accuracy: 0.7266\n",
      "Epoch 1030/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5628 - accuracy: 0.7821 - val_loss: 0.7218 - val_accuracy: 0.7256\n",
      "Epoch 1031/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5656 - accuracy: 0.7823 - val_loss: 0.7355 - val_accuracy: 0.7080\n",
      "Epoch 1032/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5635 - accuracy: 0.7789 - val_loss: 0.7384 - val_accuracy: 0.7012\n",
      "Epoch 1033/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5482 - accuracy: 0.7887 - val_loss: 0.7168 - val_accuracy: 0.7129\n",
      "Epoch 1034/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5623 - accuracy: 0.7789 - val_loss: 0.6980 - val_accuracy: 0.7236\n",
      "Epoch 1035/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5590 - accuracy: 0.7867 - val_loss: 0.6836 - val_accuracy: 0.7393\n",
      "Epoch 1036/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5656 - accuracy: 0.7911 - val_loss: 0.6853 - val_accuracy: 0.7363\n",
      "Epoch 1037/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5582 - accuracy: 0.7892 - val_loss: 0.6991 - val_accuracy: 0.7324\n",
      "Epoch 1038/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5481 - accuracy: 0.7921 - val_loss: 0.7090 - val_accuracy: 0.7285\n",
      "Epoch 1039/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5426 - accuracy: 0.7957 - val_loss: 0.7164 - val_accuracy: 0.7275\n",
      "Epoch 1040/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5599 - accuracy: 0.7791 - val_loss: 0.7237 - val_accuracy: 0.7246\n",
      "Epoch 1041/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5505 - accuracy: 0.7877 - val_loss: 0.7242 - val_accuracy: 0.7256\n",
      "Epoch 1042/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5573 - accuracy: 0.7899 - val_loss: 0.7142 - val_accuracy: 0.7295\n",
      "Epoch 1043/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5502 - accuracy: 0.7860 - val_loss: 0.6977 - val_accuracy: 0.7334\n",
      "Epoch 1044/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5484 - accuracy: 0.7950 - val_loss: 0.6792 - val_accuracy: 0.7432\n",
      "Epoch 1045/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5408 - accuracy: 0.7901 - val_loss: 0.6764 - val_accuracy: 0.7490\n",
      "Epoch 1046/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5433 - accuracy: 0.7874 - val_loss: 0.6880 - val_accuracy: 0.7402\n",
      "Epoch 1047/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5475 - accuracy: 0.7901 - val_loss: 0.6962 - val_accuracy: 0.7324\n",
      "Epoch 1048/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5351 - accuracy: 0.7994 - val_loss: 0.7031 - val_accuracy: 0.7334\n",
      "Epoch 1049/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5460 - accuracy: 0.7999 - val_loss: 0.6964 - val_accuracy: 0.7373\n",
      "Epoch 1050/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5420 - accuracy: 0.7975 - val_loss: 0.6998 - val_accuracy: 0.7344\n",
      "Epoch 1051/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5346 - accuracy: 0.7970 - val_loss: 0.7081 - val_accuracy: 0.7314\n",
      "Epoch 1052/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5422 - accuracy: 0.7984 - val_loss: 0.7144 - val_accuracy: 0.7275\n",
      "Epoch 1053/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5380 - accuracy: 0.7950 - val_loss: 0.7134 - val_accuracy: 0.7246\n",
      "Epoch 1054/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5326 - accuracy: 0.8004 - val_loss: 0.7085 - val_accuracy: 0.7275\n",
      "Epoch 1055/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5466 - accuracy: 0.7904 - val_loss: 0.7032 - val_accuracy: 0.7305\n",
      "Epoch 1056/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5262 - accuracy: 0.7994 - val_loss: 0.6964 - val_accuracy: 0.7373\n",
      "Epoch 1057/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5400 - accuracy: 0.7948 - val_loss: 0.6922 - val_accuracy: 0.7393\n",
      "Epoch 1058/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5217 - accuracy: 0.8009 - val_loss: 0.6881 - val_accuracy: 0.7451\n",
      "Epoch 1059/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5349 - accuracy: 0.8026 - val_loss: 0.6888 - val_accuracy: 0.7441\n",
      "Epoch 1060/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5314 - accuracy: 0.7982 - val_loss: 0.6942 - val_accuracy: 0.7422\n",
      "Epoch 1061/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5275 - accuracy: 0.7950 - val_loss: 0.7022 - val_accuracy: 0.7422\n",
      "Epoch 1062/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5233 - accuracy: 0.8023 - val_loss: 0.7123 - val_accuracy: 0.7354\n",
      "Epoch 1063/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5258 - accuracy: 0.8004 - val_loss: 0.7235 - val_accuracy: 0.7344\n",
      "Epoch 1064/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5314 - accuracy: 0.7967 - val_loss: 0.7288 - val_accuracy: 0.7324\n",
      "Epoch 1065/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5162 - accuracy: 0.7984 - val_loss: 0.7268 - val_accuracy: 0.7344\n",
      "Epoch 1066/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5115 - accuracy: 0.8038 - val_loss: 0.7178 - val_accuracy: 0.7383\n",
      "Epoch 1067/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5100 - accuracy: 0.8111 - val_loss: 0.7061 - val_accuracy: 0.7422\n",
      "Epoch 1068/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5268 - accuracy: 0.8060 - val_loss: 0.6978 - val_accuracy: 0.7471\n",
      "Epoch 1069/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5205 - accuracy: 0.8011 - val_loss: 0.6968 - val_accuracy: 0.7461\n",
      "Epoch 1070/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5101 - accuracy: 0.8107 - val_loss: 0.6926 - val_accuracy: 0.7490\n",
      "Epoch 1071/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5062 - accuracy: 0.8067 - val_loss: 0.6890 - val_accuracy: 0.7441\n",
      "Epoch 1072/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5250 - accuracy: 0.8016 - val_loss: 0.6857 - val_accuracy: 0.7441\n",
      "Epoch 1073/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5198 - accuracy: 0.8058 - val_loss: 0.6809 - val_accuracy: 0.7451\n",
      "Epoch 1074/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5216 - accuracy: 0.7982 - val_loss: 0.6820 - val_accuracy: 0.7393\n",
      "Epoch 1075/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5256 - accuracy: 0.8026 - val_loss: 0.6853 - val_accuracy: 0.7422\n",
      "Epoch 1076/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5252 - accuracy: 0.8028 - val_loss: 0.6876 - val_accuracy: 0.7422\n",
      "Epoch 1077/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5211 - accuracy: 0.8043 - val_loss: 0.6914 - val_accuracy: 0.7363\n",
      "Epoch 1078/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5173 - accuracy: 0.8082 - val_loss: 0.6908 - val_accuracy: 0.7354\n",
      "Epoch 1079/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5324 - accuracy: 0.8021 - val_loss: 0.6871 - val_accuracy: 0.7334\n",
      "Epoch 1080/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5195 - accuracy: 0.8028 - val_loss: 0.6785 - val_accuracy: 0.7373\n",
      "Epoch 1081/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5209 - accuracy: 0.8067 - val_loss: 0.6749 - val_accuracy: 0.7402\n",
      "Epoch 1082/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5206 - accuracy: 0.8050 - val_loss: 0.6849 - val_accuracy: 0.7402\n",
      "Epoch 1083/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5140 - accuracy: 0.8028 - val_loss: 0.7013 - val_accuracy: 0.7246\n",
      "Epoch 1084/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5112 - accuracy: 0.8097 - val_loss: 0.7146 - val_accuracy: 0.7129\n",
      "Epoch 1085/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5139 - accuracy: 0.8026 - val_loss: 0.7068 - val_accuracy: 0.7158\n",
      "Epoch 1086/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5192 - accuracy: 0.8072 - val_loss: 0.6907 - val_accuracy: 0.7334\n",
      "Epoch 1087/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5132 - accuracy: 0.8085 - val_loss: 0.6800 - val_accuracy: 0.7520\n",
      "Epoch 1088/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5048 - accuracy: 0.8072 - val_loss: 0.6746 - val_accuracy: 0.7559\n",
      "Epoch 1089/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5192 - accuracy: 0.8058 - val_loss: 0.6752 - val_accuracy: 0.7559\n",
      "Epoch 1090/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5173 - accuracy: 0.8077 - val_loss: 0.6772 - val_accuracy: 0.7529\n",
      "Epoch 1091/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5183 - accuracy: 0.8124 - val_loss: 0.6794 - val_accuracy: 0.7539\n",
      "Epoch 1092/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5027 - accuracy: 0.8131 - val_loss: 0.6776 - val_accuracy: 0.7490\n",
      "Epoch 1093/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5138 - accuracy: 0.8136 - val_loss: 0.6801 - val_accuracy: 0.7529\n",
      "Epoch 1094/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5173 - accuracy: 0.8067 - val_loss: 0.6856 - val_accuracy: 0.7529\n",
      "Epoch 1095/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4954 - accuracy: 0.8114 - val_loss: 0.6916 - val_accuracy: 0.7471\n",
      "Epoch 1096/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5064 - accuracy: 0.8133 - val_loss: 0.7021 - val_accuracy: 0.7500\n",
      "Epoch 1097/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5137 - accuracy: 0.8053 - val_loss: 0.7147 - val_accuracy: 0.7363\n",
      "Epoch 1098/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5185 - accuracy: 0.8124 - val_loss: 0.7366 - val_accuracy: 0.7041\n",
      "Epoch 1099/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4934 - accuracy: 0.8138 - val_loss: 0.7546 - val_accuracy: 0.6816\n",
      "Epoch 1100/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4972 - accuracy: 0.8131 - val_loss: 0.7586 - val_accuracy: 0.6738\n",
      "Epoch 1101/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5122 - accuracy: 0.8094 - val_loss: 0.7476 - val_accuracy: 0.6826\n",
      "Epoch 1102/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5140 - accuracy: 0.8041 - val_loss: 0.7217 - val_accuracy: 0.7139\n",
      "Epoch 1103/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5159 - accuracy: 0.8038 - val_loss: 0.6987 - val_accuracy: 0.7275\n",
      "Epoch 1104/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5222 - accuracy: 0.8060 - val_loss: 0.6792 - val_accuracy: 0.7510\n",
      "Epoch 1105/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5096 - accuracy: 0.8177 - val_loss: 0.6719 - val_accuracy: 0.7549\n",
      "Epoch 1106/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4983 - accuracy: 0.8129 - val_loss: 0.6742 - val_accuracy: 0.7500\n",
      "Epoch 1107/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4974 - accuracy: 0.8182 - val_loss: 0.6829 - val_accuracy: 0.7422\n",
      "Epoch 1108/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4994 - accuracy: 0.8158 - val_loss: 0.6862 - val_accuracy: 0.7383\n",
      "Epoch 1109/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4952 - accuracy: 0.8234 - val_loss: 0.6848 - val_accuracy: 0.7354\n",
      "Epoch 1110/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4876 - accuracy: 0.8182 - val_loss: 0.6835 - val_accuracy: 0.7422\n",
      "Epoch 1111/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4959 - accuracy: 0.8197 - val_loss: 0.6932 - val_accuracy: 0.7354\n",
      "Epoch 1112/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5011 - accuracy: 0.8160 - val_loss: 0.6940 - val_accuracy: 0.7363\n",
      "Epoch 1113/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5030 - accuracy: 0.8180 - val_loss: 0.6953 - val_accuracy: 0.7363\n",
      "Epoch 1114/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5072 - accuracy: 0.8087 - val_loss: 0.6931 - val_accuracy: 0.7324\n",
      "Epoch 1115/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4957 - accuracy: 0.8119 - val_loss: 0.6826 - val_accuracy: 0.7354\n",
      "Epoch 1116/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5100 - accuracy: 0.8058 - val_loss: 0.6715 - val_accuracy: 0.7393\n",
      "Epoch 1117/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4931 - accuracy: 0.8155 - val_loss: 0.6665 - val_accuracy: 0.7471\n",
      "Epoch 1118/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5041 - accuracy: 0.8080 - val_loss: 0.6703 - val_accuracy: 0.7480\n",
      "Epoch 1119/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5120 - accuracy: 0.8153 - val_loss: 0.6833 - val_accuracy: 0.7373\n",
      "Epoch 1120/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5003 - accuracy: 0.8151 - val_loss: 0.6935 - val_accuracy: 0.7324\n",
      "Epoch 1121/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4969 - accuracy: 0.8097 - val_loss: 0.6943 - val_accuracy: 0.7314\n",
      "Epoch 1122/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4999 - accuracy: 0.8085 - val_loss: 0.6766 - val_accuracy: 0.7412\n",
      "Epoch 1123/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4924 - accuracy: 0.8168 - val_loss: 0.6607 - val_accuracy: 0.7412\n",
      "Epoch 1124/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5091 - accuracy: 0.8146 - val_loss: 0.6605 - val_accuracy: 0.7363\n",
      "Epoch 1125/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5069 - accuracy: 0.8089 - val_loss: 0.6713 - val_accuracy: 0.7354\n",
      "Epoch 1126/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5103 - accuracy: 0.8102 - val_loss: 0.6748 - val_accuracy: 0.7324\n",
      "Epoch 1127/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4941 - accuracy: 0.8143 - val_loss: 0.6785 - val_accuracy: 0.7354\n",
      "Epoch 1128/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5028 - accuracy: 0.8111 - val_loss: 0.6748 - val_accuracy: 0.7334\n",
      "Epoch 1129/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5137 - accuracy: 0.8119 - val_loss: 0.6692 - val_accuracy: 0.7363\n",
      "Epoch 1130/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5068 - accuracy: 0.8126 - val_loss: 0.6693 - val_accuracy: 0.7373\n",
      "Epoch 1131/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4807 - accuracy: 0.8199 - val_loss: 0.6723 - val_accuracy: 0.7354\n",
      "Epoch 1132/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4999 - accuracy: 0.8136 - val_loss: 0.6889 - val_accuracy: 0.7412\n",
      "Epoch 1133/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5035 - accuracy: 0.8163 - val_loss: 0.7172 - val_accuracy: 0.7314\n",
      "Epoch 1134/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4950 - accuracy: 0.8185 - val_loss: 0.7406 - val_accuracy: 0.7168\n",
      "Epoch 1135/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4946 - accuracy: 0.8087 - val_loss: 0.7416 - val_accuracy: 0.7090\n",
      "Epoch 1136/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4774 - accuracy: 0.8194 - val_loss: 0.7141 - val_accuracy: 0.7178\n",
      "Epoch 1137/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4962 - accuracy: 0.8146 - val_loss: 0.6886 - val_accuracy: 0.7246\n",
      "Epoch 1138/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4950 - accuracy: 0.8163 - val_loss: 0.6787 - val_accuracy: 0.7402\n",
      "Epoch 1139/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4956 - accuracy: 0.8216 - val_loss: 0.6821 - val_accuracy: 0.7412\n",
      "Epoch 1140/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5052 - accuracy: 0.8087 - val_loss: 0.6856 - val_accuracy: 0.7393\n",
      "Epoch 1141/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4799 - accuracy: 0.8163 - val_loss: 0.6861 - val_accuracy: 0.7441\n",
      "Epoch 1142/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4989 - accuracy: 0.8099 - val_loss: 0.6849 - val_accuracy: 0.7480\n",
      "Epoch 1143/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4924 - accuracy: 0.8097 - val_loss: 0.6837 - val_accuracy: 0.7480\n",
      "Epoch 1144/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5011 - accuracy: 0.8121 - val_loss: 0.6850 - val_accuracy: 0.7500\n",
      "Epoch 1145/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4930 - accuracy: 0.8163 - val_loss: 0.6863 - val_accuracy: 0.7510\n",
      "Epoch 1146/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4942 - accuracy: 0.8129 - val_loss: 0.6801 - val_accuracy: 0.7490\n",
      "Epoch 1147/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4927 - accuracy: 0.8143 - val_loss: 0.6773 - val_accuracy: 0.7529\n",
      "Epoch 1148/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4861 - accuracy: 0.8170 - val_loss: 0.6737 - val_accuracy: 0.7480\n",
      "Epoch 1149/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4971 - accuracy: 0.8180 - val_loss: 0.6634 - val_accuracy: 0.7412\n",
      "Epoch 1150/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4763 - accuracy: 0.8229 - val_loss: 0.6557 - val_accuracy: 0.7422\n",
      "Epoch 1151/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4940 - accuracy: 0.8192 - val_loss: 0.6503 - val_accuracy: 0.7422\n",
      "Epoch 1152/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4922 - accuracy: 0.8131 - val_loss: 0.6506 - val_accuracy: 0.7500\n",
      "Epoch 1153/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4812 - accuracy: 0.8234 - val_loss: 0.6526 - val_accuracy: 0.7471\n",
      "Epoch 1154/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4830 - accuracy: 0.8212 - val_loss: 0.6558 - val_accuracy: 0.7451\n",
      "Epoch 1155/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5070 - accuracy: 0.8146 - val_loss: 0.6626 - val_accuracy: 0.7461\n",
      "Epoch 1156/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4845 - accuracy: 0.8204 - val_loss: 0.6673 - val_accuracy: 0.7461\n",
      "Epoch 1157/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4843 - accuracy: 0.8216 - val_loss: 0.6700 - val_accuracy: 0.7441\n",
      "Epoch 1158/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5069 - accuracy: 0.8165 - val_loss: 0.6726 - val_accuracy: 0.7520\n",
      "Epoch 1159/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4896 - accuracy: 0.8165 - val_loss: 0.6710 - val_accuracy: 0.7539\n",
      "Epoch 1160/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4963 - accuracy: 0.8138 - val_loss: 0.6659 - val_accuracy: 0.7480\n",
      "Epoch 1161/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4939 - accuracy: 0.8155 - val_loss: 0.6672 - val_accuracy: 0.7500\n",
      "Epoch 1162/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4979 - accuracy: 0.8192 - val_loss: 0.6781 - val_accuracy: 0.7490\n",
      "Epoch 1163/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4731 - accuracy: 0.8234 - val_loss: 0.6916 - val_accuracy: 0.7471\n",
      "Epoch 1164/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4983 - accuracy: 0.8221 - val_loss: 0.6813 - val_accuracy: 0.7480\n",
      "Epoch 1165/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4865 - accuracy: 0.8172 - val_loss: 0.6652 - val_accuracy: 0.7568\n",
      "Epoch 1166/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4870 - accuracy: 0.8168 - val_loss: 0.6583 - val_accuracy: 0.7559\n",
      "Epoch 1167/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4860 - accuracy: 0.8199 - val_loss: 0.6586 - val_accuracy: 0.7578\n",
      "Epoch 1168/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4884 - accuracy: 0.8182 - val_loss: 0.6656 - val_accuracy: 0.7451\n",
      "Epoch 1169/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4899 - accuracy: 0.8202 - val_loss: 0.6704 - val_accuracy: 0.7471\n",
      "Epoch 1170/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4915 - accuracy: 0.8151 - val_loss: 0.6776 - val_accuracy: 0.7383\n",
      "Epoch 1171/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4823 - accuracy: 0.8236 - val_loss: 0.6803 - val_accuracy: 0.7393\n",
      "Epoch 1172/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4859 - accuracy: 0.8224 - val_loss: 0.6830 - val_accuracy: 0.7402\n",
      "Epoch 1173/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4841 - accuracy: 0.8165 - val_loss: 0.6811 - val_accuracy: 0.7373\n",
      "Epoch 1174/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4919 - accuracy: 0.8129 - val_loss: 0.6835 - val_accuracy: 0.7383\n",
      "Epoch 1175/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4914 - accuracy: 0.8190 - val_loss: 0.6845 - val_accuracy: 0.7354\n",
      "Epoch 1176/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4718 - accuracy: 0.8263 - val_loss: 0.6818 - val_accuracy: 0.7363\n",
      "Epoch 1177/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4808 - accuracy: 0.8295 - val_loss: 0.6779 - val_accuracy: 0.7412\n",
      "Epoch 1178/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4895 - accuracy: 0.8158 - val_loss: 0.6795 - val_accuracy: 0.7393\n",
      "Epoch 1179/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4916 - accuracy: 0.8151 - val_loss: 0.6756 - val_accuracy: 0.7383\n",
      "Epoch 1180/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4789 - accuracy: 0.8251 - val_loss: 0.6690 - val_accuracy: 0.7393\n",
      "Epoch 1181/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4791 - accuracy: 0.8229 - val_loss: 0.6677 - val_accuracy: 0.7432\n",
      "Epoch 1182/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4845 - accuracy: 0.8175 - val_loss: 0.6721 - val_accuracy: 0.7451\n",
      "Epoch 1183/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4914 - accuracy: 0.8175 - val_loss: 0.6766 - val_accuracy: 0.7578\n",
      "Epoch 1184/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4725 - accuracy: 0.8221 - val_loss: 0.6787 - val_accuracy: 0.7588\n",
      "Epoch 1185/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4726 - accuracy: 0.8221 - val_loss: 0.6761 - val_accuracy: 0.7471\n",
      "Epoch 1186/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4827 - accuracy: 0.8202 - val_loss: 0.6716 - val_accuracy: 0.7588\n",
      "Epoch 1187/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4755 - accuracy: 0.8260 - val_loss: 0.6701 - val_accuracy: 0.7539\n",
      "Epoch 1188/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4730 - accuracy: 0.8248 - val_loss: 0.6749 - val_accuracy: 0.7393\n",
      "Epoch 1189/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4700 - accuracy: 0.8282 - val_loss: 0.6792 - val_accuracy: 0.7363\n",
      "Epoch 1190/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4812 - accuracy: 0.8204 - val_loss: 0.6756 - val_accuracy: 0.7354\n",
      "Epoch 1191/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4761 - accuracy: 0.8246 - val_loss: 0.6610 - val_accuracy: 0.7441\n",
      "Epoch 1192/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4723 - accuracy: 0.8234 - val_loss: 0.6508 - val_accuracy: 0.7451\n",
      "Epoch 1193/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4827 - accuracy: 0.8165 - val_loss: 0.6502 - val_accuracy: 0.7422\n",
      "Epoch 1194/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4820 - accuracy: 0.8194 - val_loss: 0.6544 - val_accuracy: 0.7373\n",
      "Epoch 1195/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4863 - accuracy: 0.8226 - val_loss: 0.6615 - val_accuracy: 0.7334\n",
      "Epoch 1196/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4819 - accuracy: 0.8253 - val_loss: 0.6666 - val_accuracy: 0.7285\n",
      "Epoch 1197/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4804 - accuracy: 0.8209 - val_loss: 0.6745 - val_accuracy: 0.7266\n",
      "Epoch 1198/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4775 - accuracy: 0.8260 - val_loss: 0.6775 - val_accuracy: 0.7275\n",
      "Epoch 1199/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4850 - accuracy: 0.8153 - val_loss: 0.6742 - val_accuracy: 0.7324\n",
      "Epoch 1200/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4765 - accuracy: 0.8290 - val_loss: 0.6731 - val_accuracy: 0.7383\n",
      "Epoch 1201/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4574 - accuracy: 0.8287 - val_loss: 0.6772 - val_accuracy: 0.7393\n",
      "Epoch 1202/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4793 - accuracy: 0.8265 - val_loss: 0.6854 - val_accuracy: 0.7344\n",
      "Epoch 1203/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4700 - accuracy: 0.8224 - val_loss: 0.6993 - val_accuracy: 0.7324\n",
      "Epoch 1204/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4651 - accuracy: 0.8331 - val_loss: 0.7111 - val_accuracy: 0.7344\n",
      "Epoch 1205/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4721 - accuracy: 0.8246 - val_loss: 0.7214 - val_accuracy: 0.7334\n",
      "Epoch 1206/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4689 - accuracy: 0.8290 - val_loss: 0.7162 - val_accuracy: 0.7324\n",
      "Epoch 1207/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4685 - accuracy: 0.8243 - val_loss: 0.6927 - val_accuracy: 0.7402\n",
      "Epoch 1208/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4821 - accuracy: 0.8221 - val_loss: 0.6715 - val_accuracy: 0.7373\n",
      "Epoch 1209/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4729 - accuracy: 0.8199 - val_loss: 0.6575 - val_accuracy: 0.7451\n",
      "Epoch 1210/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4888 - accuracy: 0.8151 - val_loss: 0.6524 - val_accuracy: 0.7529\n",
      "Epoch 1211/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4807 - accuracy: 0.8260 - val_loss: 0.6571 - val_accuracy: 0.7422\n",
      "Epoch 1212/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4710 - accuracy: 0.8265 - val_loss: 0.6737 - val_accuracy: 0.7412\n",
      "Epoch 1213/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4644 - accuracy: 0.8258 - val_loss: 0.6861 - val_accuracy: 0.7393\n",
      "Epoch 1214/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4655 - accuracy: 0.8246 - val_loss: 0.6853 - val_accuracy: 0.7383\n",
      "Epoch 1215/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4763 - accuracy: 0.8251 - val_loss: 0.6752 - val_accuracy: 0.7490\n",
      "Epoch 1216/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4626 - accuracy: 0.8319 - val_loss: 0.6678 - val_accuracy: 0.7412\n",
      "Epoch 1217/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4711 - accuracy: 0.8221 - val_loss: 0.6665 - val_accuracy: 0.7432\n",
      "Epoch 1218/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4711 - accuracy: 0.8214 - val_loss: 0.6715 - val_accuracy: 0.7441\n",
      "Epoch 1219/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4631 - accuracy: 0.8270 - val_loss: 0.6824 - val_accuracy: 0.7422\n",
      "Epoch 1220/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4667 - accuracy: 0.8268 - val_loss: 0.6885 - val_accuracy: 0.7490\n",
      "Epoch 1221/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4637 - accuracy: 0.8270 - val_loss: 0.6890 - val_accuracy: 0.7490\n",
      "Epoch 1222/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4777 - accuracy: 0.8231 - val_loss: 0.6894 - val_accuracy: 0.7480\n",
      "Epoch 1223/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4700 - accuracy: 0.8292 - val_loss: 0.6879 - val_accuracy: 0.7500\n",
      "Epoch 1224/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4611 - accuracy: 0.8312 - val_loss: 0.6892 - val_accuracy: 0.7461\n",
      "Epoch 1225/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4613 - accuracy: 0.8339 - val_loss: 0.6955 - val_accuracy: 0.7422\n",
      "Epoch 1226/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4638 - accuracy: 0.8309 - val_loss: 0.7087 - val_accuracy: 0.7412\n",
      "Epoch 1227/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4738 - accuracy: 0.8251 - val_loss: 0.7238 - val_accuracy: 0.7393\n",
      "Epoch 1228/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4593 - accuracy: 0.8241 - val_loss: 0.7105 - val_accuracy: 0.7383\n",
      "Epoch 1229/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4738 - accuracy: 0.8229 - val_loss: 0.6949 - val_accuracy: 0.7432\n",
      "Epoch 1230/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4723 - accuracy: 0.8258 - val_loss: 0.6752 - val_accuracy: 0.7461\n",
      "Epoch 1231/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4570 - accuracy: 0.8309 - val_loss: 0.6627 - val_accuracy: 0.7432\n",
      "Epoch 1232/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4612 - accuracy: 0.8331 - val_loss: 0.6650 - val_accuracy: 0.7383\n",
      "Epoch 1233/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4727 - accuracy: 0.8256 - val_loss: 0.6721 - val_accuracy: 0.7295\n",
      "Epoch 1234/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4804 - accuracy: 0.8187 - val_loss: 0.6652 - val_accuracy: 0.7354\n",
      "Epoch 1235/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4766 - accuracy: 0.8202 - val_loss: 0.6599 - val_accuracy: 0.7305\n",
      "Epoch 1236/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4836 - accuracy: 0.8229 - val_loss: 0.6611 - val_accuracy: 0.7334\n",
      "Epoch 1237/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4736 - accuracy: 0.8221 - val_loss: 0.6718 - val_accuracy: 0.7412\n",
      "Epoch 1238/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4697 - accuracy: 0.8270 - val_loss: 0.6907 - val_accuracy: 0.7383\n",
      "Epoch 1239/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4669 - accuracy: 0.8292 - val_loss: 0.7070 - val_accuracy: 0.7344\n",
      "Epoch 1240/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4767 - accuracy: 0.8268 - val_loss: 0.7072 - val_accuracy: 0.7363\n",
      "Epoch 1241/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4715 - accuracy: 0.8280 - val_loss: 0.7029 - val_accuracy: 0.7412\n",
      "Epoch 1242/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4569 - accuracy: 0.8263 - val_loss: 0.7023 - val_accuracy: 0.7402\n",
      "Epoch 1243/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4671 - accuracy: 0.8309 - val_loss: 0.6999 - val_accuracy: 0.7363\n",
      "Epoch 1244/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4608 - accuracy: 0.8287 - val_loss: 0.6965 - val_accuracy: 0.7314\n",
      "Epoch 1245/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4640 - accuracy: 0.8256 - val_loss: 0.6914 - val_accuracy: 0.7314\n",
      "Epoch 1246/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4751 - accuracy: 0.8229 - val_loss: 0.6903 - val_accuracy: 0.7314\n",
      "Epoch 1247/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4669 - accuracy: 0.8319 - val_loss: 0.6963 - val_accuracy: 0.7305\n",
      "Epoch 1248/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4668 - accuracy: 0.8270 - val_loss: 0.7071 - val_accuracy: 0.7324\n",
      "Epoch 1249/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4632 - accuracy: 0.8290 - val_loss: 0.7109 - val_accuracy: 0.7305\n",
      "Epoch 1250/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4685 - accuracy: 0.8260 - val_loss: 0.7098 - val_accuracy: 0.7324\n",
      "Epoch 1251/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4532 - accuracy: 0.8329 - val_loss: 0.7018 - val_accuracy: 0.7393\n",
      "Epoch 1252/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4486 - accuracy: 0.8334 - val_loss: 0.6974 - val_accuracy: 0.7432\n",
      "Epoch 1253/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4659 - accuracy: 0.8302 - val_loss: 0.6941 - val_accuracy: 0.7500\n",
      "Epoch 1254/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4627 - accuracy: 0.8268 - val_loss: 0.6884 - val_accuracy: 0.7500\n",
      "Epoch 1255/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4473 - accuracy: 0.8295 - val_loss: 0.6929 - val_accuracy: 0.7520\n",
      "Epoch 1256/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4718 - accuracy: 0.8285 - val_loss: 0.7021 - val_accuracy: 0.7461\n",
      "Epoch 1257/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4638 - accuracy: 0.8234 - val_loss: 0.7086 - val_accuracy: 0.7344\n",
      "Epoch 1258/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4605 - accuracy: 0.8238 - val_loss: 0.7086 - val_accuracy: 0.7354\n",
      "Epoch 1259/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4598 - accuracy: 0.8290 - val_loss: 0.6973 - val_accuracy: 0.7412\n",
      "Epoch 1260/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4560 - accuracy: 0.8307 - val_loss: 0.6730 - val_accuracy: 0.7451\n",
      "Epoch 1261/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4547 - accuracy: 0.8295 - val_loss: 0.6576 - val_accuracy: 0.7471\n",
      "Epoch 1262/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4623 - accuracy: 0.8295 - val_loss: 0.6537 - val_accuracy: 0.7471\n",
      "Epoch 1263/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4623 - accuracy: 0.8302 - val_loss: 0.6571 - val_accuracy: 0.7451\n",
      "Epoch 1264/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4685 - accuracy: 0.8246 - val_loss: 0.6692 - val_accuracy: 0.7441\n",
      "Epoch 1265/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4647 - accuracy: 0.8322 - val_loss: 0.6830 - val_accuracy: 0.7422\n",
      "Epoch 1266/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4438 - accuracy: 0.8351 - val_loss: 0.6904 - val_accuracy: 0.7412\n",
      "Epoch 1267/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4663 - accuracy: 0.8278 - val_loss: 0.6805 - val_accuracy: 0.7266\n",
      "Epoch 1268/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4615 - accuracy: 0.8297 - val_loss: 0.6759 - val_accuracy: 0.7285\n",
      "Epoch 1269/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4643 - accuracy: 0.8326 - val_loss: 0.7107 - val_accuracy: 0.7129\n",
      "Epoch 1270/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4517 - accuracy: 0.8336 - val_loss: 0.7460 - val_accuracy: 0.7002\n",
      "Epoch 1271/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4614 - accuracy: 0.8234 - val_loss: 0.7517 - val_accuracy: 0.6982\n",
      "Epoch 1272/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4604 - accuracy: 0.8280 - val_loss: 0.7269 - val_accuracy: 0.7021\n",
      "Epoch 1273/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4612 - accuracy: 0.8309 - val_loss: 0.7046 - val_accuracy: 0.7178\n",
      "Epoch 1274/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4489 - accuracy: 0.8317 - val_loss: 0.6840 - val_accuracy: 0.7334\n",
      "Epoch 1275/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4544 - accuracy: 0.8314 - val_loss: 0.6695 - val_accuracy: 0.7451\n",
      "Epoch 1276/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4617 - accuracy: 0.8297 - val_loss: 0.6653 - val_accuracy: 0.7480\n",
      "Epoch 1277/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4717 - accuracy: 0.8256 - val_loss: 0.6595 - val_accuracy: 0.7412\n",
      "Epoch 1278/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4746 - accuracy: 0.8300 - val_loss: 0.6515 - val_accuracy: 0.7471\n",
      "Epoch 1279/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4739 - accuracy: 0.8241 - val_loss: 0.6425 - val_accuracy: 0.7480\n",
      "Epoch 1280/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4438 - accuracy: 0.8351 - val_loss: 0.6411 - val_accuracy: 0.7529\n",
      "Epoch 1281/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4432 - accuracy: 0.8380 - val_loss: 0.6476 - val_accuracy: 0.7539\n",
      "Epoch 1282/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4550 - accuracy: 0.8297 - val_loss: 0.6564 - val_accuracy: 0.7510\n",
      "Epoch 1283/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4480 - accuracy: 0.8319 - val_loss: 0.6667 - val_accuracy: 0.7500\n",
      "Epoch 1284/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4403 - accuracy: 0.8368 - val_loss: 0.6763 - val_accuracy: 0.7500\n",
      "Epoch 1285/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4487 - accuracy: 0.8346 - val_loss: 0.6732 - val_accuracy: 0.7500\n",
      "Epoch 1286/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4537 - accuracy: 0.8383 - val_loss: 0.6687 - val_accuracy: 0.7490\n",
      "Epoch 1287/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4651 - accuracy: 0.8334 - val_loss: 0.6610 - val_accuracy: 0.7510\n",
      "Epoch 1288/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4558 - accuracy: 0.8387 - val_loss: 0.6606 - val_accuracy: 0.7500\n",
      "Epoch 1289/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4451 - accuracy: 0.8361 - val_loss: 0.6683 - val_accuracy: 0.7461\n",
      "Epoch 1290/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4589 - accuracy: 0.8282 - val_loss: 0.6852 - val_accuracy: 0.7412\n",
      "Epoch 1291/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4656 - accuracy: 0.8314 - val_loss: 0.6916 - val_accuracy: 0.7363\n",
      "Epoch 1292/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4395 - accuracy: 0.8341 - val_loss: 0.6935 - val_accuracy: 0.7432\n",
      "Epoch 1293/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4454 - accuracy: 0.8358 - val_loss: 0.6940 - val_accuracy: 0.7480\n",
      "Epoch 1294/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4470 - accuracy: 0.8353 - val_loss: 0.7016 - val_accuracy: 0.7383\n",
      "Epoch 1295/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4455 - accuracy: 0.8331 - val_loss: 0.7507 - val_accuracy: 0.6885\n",
      "Epoch 1296/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4520 - accuracy: 0.8385 - val_loss: 0.8137 - val_accuracy: 0.6523\n",
      "Epoch 1297/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4610 - accuracy: 0.8287 - val_loss: 0.7963 - val_accuracy: 0.6631\n",
      "Epoch 1298/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4542 - accuracy: 0.8373 - val_loss: 0.7496 - val_accuracy: 0.6973\n",
      "Epoch 1299/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4378 - accuracy: 0.8402 - val_loss: 0.7239 - val_accuracy: 0.7236\n",
      "Epoch 1300/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4507 - accuracy: 0.8317 - val_loss: 0.7172 - val_accuracy: 0.7354\n",
      "Epoch 1301/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4470 - accuracy: 0.8387 - val_loss: 0.7191 - val_accuracy: 0.7402\n",
      "Epoch 1302/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4498 - accuracy: 0.8339 - val_loss: 0.7310 - val_accuracy: 0.7451\n",
      "Epoch 1303/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4425 - accuracy: 0.8351 - val_loss: 0.7376 - val_accuracy: 0.7324\n",
      "Epoch 1304/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4414 - accuracy: 0.8358 - val_loss: 0.7228 - val_accuracy: 0.7334\n",
      "Epoch 1305/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4563 - accuracy: 0.8392 - val_loss: 0.6943 - val_accuracy: 0.7480\n",
      "Epoch 1306/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4504 - accuracy: 0.8356 - val_loss: 0.6674 - val_accuracy: 0.7646\n",
      "Epoch 1307/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4392 - accuracy: 0.8341 - val_loss: 0.6625 - val_accuracy: 0.7705\n",
      "Epoch 1308/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4437 - accuracy: 0.8395 - val_loss: 0.6728 - val_accuracy: 0.7637\n",
      "Epoch 1309/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4496 - accuracy: 0.8400 - val_loss: 0.6789 - val_accuracy: 0.7529\n",
      "Epoch 1310/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4491 - accuracy: 0.8378 - val_loss: 0.6874 - val_accuracy: 0.7471\n",
      "Epoch 1311/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4489 - accuracy: 0.8348 - val_loss: 0.6860 - val_accuracy: 0.7461\n",
      "Epoch 1312/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4405 - accuracy: 0.8387 - val_loss: 0.6816 - val_accuracy: 0.7461\n",
      "Epoch 1313/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4639 - accuracy: 0.8329 - val_loss: 0.6759 - val_accuracy: 0.7471\n",
      "Epoch 1314/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4390 - accuracy: 0.8385 - val_loss: 0.6724 - val_accuracy: 0.7490\n",
      "Epoch 1315/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4379 - accuracy: 0.8329 - val_loss: 0.6692 - val_accuracy: 0.7490\n",
      "Epoch 1316/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4468 - accuracy: 0.8353 - val_loss: 0.6621 - val_accuracy: 0.7500\n",
      "Epoch 1317/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4479 - accuracy: 0.8361 - val_loss: 0.6560 - val_accuracy: 0.7539\n",
      "Epoch 1318/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4515 - accuracy: 0.8344 - val_loss: 0.6639 - val_accuracy: 0.7578\n",
      "Epoch 1319/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4391 - accuracy: 0.8366 - val_loss: 0.6801 - val_accuracy: 0.7490\n",
      "Epoch 1320/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4475 - accuracy: 0.8395 - val_loss: 0.6854 - val_accuracy: 0.7451\n",
      "Epoch 1321/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4385 - accuracy: 0.8395 - val_loss: 0.6810 - val_accuracy: 0.7471\n",
      "Epoch 1322/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4329 - accuracy: 0.8422 - val_loss: 0.6672 - val_accuracy: 0.7480\n",
      "Epoch 1323/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4497 - accuracy: 0.8319 - val_loss: 0.6578 - val_accuracy: 0.7432\n",
      "Epoch 1324/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4365 - accuracy: 0.8422 - val_loss: 0.6534 - val_accuracy: 0.7451\n",
      "Epoch 1325/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4407 - accuracy: 0.8380 - val_loss: 0.6476 - val_accuracy: 0.7461\n",
      "Epoch 1326/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4474 - accuracy: 0.8300 - val_loss: 0.6509 - val_accuracy: 0.7510\n",
      "Epoch 1327/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4370 - accuracy: 0.8427 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
      "Epoch 1328/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4394 - accuracy: 0.8368 - val_loss: 0.6683 - val_accuracy: 0.7510\n",
      "Epoch 1329/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4333 - accuracy: 0.8395 - val_loss: 0.6746 - val_accuracy: 0.7568\n",
      "Epoch 1330/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4466 - accuracy: 0.8385 - val_loss: 0.6827 - val_accuracy: 0.7490\n",
      "Epoch 1331/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4444 - accuracy: 0.8368 - val_loss: 0.7022 - val_accuracy: 0.7383\n",
      "Epoch 1332/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4223 - accuracy: 0.8444 - val_loss: 0.7185 - val_accuracy: 0.7178\n",
      "Epoch 1333/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4394 - accuracy: 0.8434 - val_loss: 0.7009 - val_accuracy: 0.7266\n",
      "Epoch 1334/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4460 - accuracy: 0.8358 - val_loss: 0.6719 - val_accuracy: 0.7412\n",
      "Epoch 1335/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4485 - accuracy: 0.8385 - val_loss: 0.6564 - val_accuracy: 0.7598\n",
      "Epoch 1336/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4438 - accuracy: 0.8383 - val_loss: 0.6565 - val_accuracy: 0.7598\n",
      "Epoch 1337/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4485 - accuracy: 0.8387 - val_loss: 0.6617 - val_accuracy: 0.7598\n",
      "Epoch 1338/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4370 - accuracy: 0.8409 - val_loss: 0.6649 - val_accuracy: 0.7500\n",
      "Epoch 1339/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4467 - accuracy: 0.8361 - val_loss: 0.6652 - val_accuracy: 0.7480\n",
      "Epoch 1340/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4470 - accuracy: 0.8302 - val_loss: 0.6634 - val_accuracy: 0.7471\n",
      "Epoch 1341/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4268 - accuracy: 0.8412 - val_loss: 0.6680 - val_accuracy: 0.7441\n",
      "Epoch 1342/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4462 - accuracy: 0.8353 - val_loss: 0.6829 - val_accuracy: 0.7412\n",
      "Epoch 1343/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4333 - accuracy: 0.8375 - val_loss: 0.6973 - val_accuracy: 0.7412\n",
      "Epoch 1344/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4523 - accuracy: 0.8463 - val_loss: 0.6943 - val_accuracy: 0.7422\n",
      "Epoch 1345/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4393 - accuracy: 0.8363 - val_loss: 0.6946 - val_accuracy: 0.7373\n",
      "Epoch 1346/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4369 - accuracy: 0.8319 - val_loss: 0.6911 - val_accuracy: 0.7422\n",
      "Epoch 1347/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4491 - accuracy: 0.8324 - val_loss: 0.6867 - val_accuracy: 0.7500\n",
      "Epoch 1348/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4408 - accuracy: 0.8368 - val_loss: 0.6789 - val_accuracy: 0.7471\n",
      "Epoch 1349/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4385 - accuracy: 0.8387 - val_loss: 0.6682 - val_accuracy: 0.7461\n",
      "Epoch 1350/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4306 - accuracy: 0.8458 - val_loss: 0.6610 - val_accuracy: 0.7461\n",
      "Epoch 1351/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4432 - accuracy: 0.8414 - val_loss: 0.6551 - val_accuracy: 0.7500\n",
      "Epoch 1352/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4297 - accuracy: 0.8466 - val_loss: 0.6533 - val_accuracy: 0.7471\n",
      "Epoch 1353/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4385 - accuracy: 0.8363 - val_loss: 0.6679 - val_accuracy: 0.7568\n",
      "Epoch 1354/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4406 - accuracy: 0.8319 - val_loss: 0.6856 - val_accuracy: 0.7568\n",
      "Epoch 1355/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4148 - accuracy: 0.8461 - val_loss: 0.7067 - val_accuracy: 0.7539\n",
      "Epoch 1356/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4330 - accuracy: 0.8419 - val_loss: 0.7194 - val_accuracy: 0.7520\n",
      "Epoch 1357/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4272 - accuracy: 0.8473 - val_loss: 0.7099 - val_accuracy: 0.7520\n",
      "Epoch 1358/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4338 - accuracy: 0.8397 - val_loss: 0.6947 - val_accuracy: 0.7529\n",
      "Epoch 1359/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4418 - accuracy: 0.8429 - val_loss: 0.6766 - val_accuracy: 0.7578\n",
      "Epoch 1360/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4396 - accuracy: 0.8456 - val_loss: 0.6652 - val_accuracy: 0.7559\n",
      "Epoch 1361/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4179 - accuracy: 0.8441 - val_loss: 0.6647 - val_accuracy: 0.7549\n",
      "Epoch 1362/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4334 - accuracy: 0.8429 - val_loss: 0.6746 - val_accuracy: 0.7461\n",
      "Epoch 1363/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4391 - accuracy: 0.8351 - val_loss: 0.6807 - val_accuracy: 0.7490\n",
      "Epoch 1364/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4380 - accuracy: 0.8375 - val_loss: 0.6798 - val_accuracy: 0.7529\n",
      "Epoch 1365/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4353 - accuracy: 0.8397 - val_loss: 0.6840 - val_accuracy: 0.7510\n",
      "Epoch 1366/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4586 - accuracy: 0.8324 - val_loss: 0.6918 - val_accuracy: 0.7480\n",
      "Epoch 1367/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4546 - accuracy: 0.8346 - val_loss: 0.7076 - val_accuracy: 0.7451\n",
      "Epoch 1368/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4407 - accuracy: 0.8390 - val_loss: 0.7280 - val_accuracy: 0.7451\n",
      "Epoch 1369/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4336 - accuracy: 0.8387 - val_loss: 0.7375 - val_accuracy: 0.7529\n",
      "Epoch 1370/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4349 - accuracy: 0.8414 - val_loss: 0.7431 - val_accuracy: 0.7510\n",
      "Epoch 1371/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4400 - accuracy: 0.8402 - val_loss: 0.7372 - val_accuracy: 0.7500\n",
      "Epoch 1372/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4344 - accuracy: 0.8383 - val_loss: 0.7187 - val_accuracy: 0.7539\n",
      "Epoch 1373/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4317 - accuracy: 0.8414 - val_loss: 0.6990 - val_accuracy: 0.7529\n",
      "Epoch 1374/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4249 - accuracy: 0.8405 - val_loss: 0.6946 - val_accuracy: 0.7578\n",
      "Epoch 1375/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4478 - accuracy: 0.8346 - val_loss: 0.7089 - val_accuracy: 0.7422\n",
      "Epoch 1376/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4235 - accuracy: 0.8458 - val_loss: 0.7061 - val_accuracy: 0.7432\n",
      "Epoch 1377/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4255 - accuracy: 0.8475 - val_loss: 0.6918 - val_accuracy: 0.7559\n",
      "Epoch 1378/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4380 - accuracy: 0.8427 - val_loss: 0.6771 - val_accuracy: 0.7588\n",
      "Epoch 1379/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4323 - accuracy: 0.8446 - val_loss: 0.6650 - val_accuracy: 0.7549\n",
      "Epoch 1380/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4302 - accuracy: 0.8417 - val_loss: 0.6703 - val_accuracy: 0.7539\n",
      "Epoch 1381/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4347 - accuracy: 0.8361 - val_loss: 0.6860 - val_accuracy: 0.7480\n",
      "Epoch 1382/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4336 - accuracy: 0.8412 - val_loss: 0.7051 - val_accuracy: 0.7471\n",
      "Epoch 1383/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4234 - accuracy: 0.8478 - val_loss: 0.7313 - val_accuracy: 0.7363\n",
      "Epoch 1384/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4302 - accuracy: 0.8412 - val_loss: 0.7291 - val_accuracy: 0.7334\n",
      "Epoch 1385/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4183 - accuracy: 0.8456 - val_loss: 0.7051 - val_accuracy: 0.7441\n",
      "Epoch 1386/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4184 - accuracy: 0.8446 - val_loss: 0.6710 - val_accuracy: 0.7549\n",
      "Epoch 1387/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4142 - accuracy: 0.8500 - val_loss: 0.6463 - val_accuracy: 0.7539\n",
      "Epoch 1388/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4241 - accuracy: 0.8488 - val_loss: 0.6468 - val_accuracy: 0.7676\n",
      "Epoch 1389/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4296 - accuracy: 0.8402 - val_loss: 0.6680 - val_accuracy: 0.7588\n",
      "Epoch 1390/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4304 - accuracy: 0.8373 - val_loss: 0.6693 - val_accuracy: 0.7656\n",
      "Epoch 1391/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4324 - accuracy: 0.8402 - val_loss: 0.6725 - val_accuracy: 0.7607\n",
      "Epoch 1392/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4276 - accuracy: 0.8449 - val_loss: 0.6877 - val_accuracy: 0.7539\n",
      "Epoch 1393/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4539 - accuracy: 0.8361 - val_loss: 0.7045 - val_accuracy: 0.7539\n",
      "Epoch 1394/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4321 - accuracy: 0.8461 - val_loss: 0.7144 - val_accuracy: 0.7461\n",
      "Epoch 1395/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4206 - accuracy: 0.8431 - val_loss: 0.7166 - val_accuracy: 0.7461\n",
      "Epoch 1396/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4308 - accuracy: 0.8446 - val_loss: 0.7169 - val_accuracy: 0.7412\n",
      "Epoch 1397/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4167 - accuracy: 0.8446 - val_loss: 0.7170 - val_accuracy: 0.7363\n",
      "Epoch 1398/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4212 - accuracy: 0.8453 - val_loss: 0.7129 - val_accuracy: 0.7393\n",
      "Epoch 1399/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4263 - accuracy: 0.8434 - val_loss: 0.7111 - val_accuracy: 0.7480\n",
      "Epoch 1400/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4258 - accuracy: 0.8444 - val_loss: 0.7135 - val_accuracy: 0.7441\n",
      "Epoch 1401/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4196 - accuracy: 0.8473 - val_loss: 0.7065 - val_accuracy: 0.7500\n",
      "Epoch 1402/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4198 - accuracy: 0.8485 - val_loss: 0.7077 - val_accuracy: 0.7490\n",
      "Epoch 1403/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4220 - accuracy: 0.8466 - val_loss: 0.7158 - val_accuracy: 0.7451\n",
      "Epoch 1404/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4213 - accuracy: 0.8485 - val_loss: 0.7333 - val_accuracy: 0.7422\n",
      "Epoch 1405/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4305 - accuracy: 0.8439 - val_loss: 0.7528 - val_accuracy: 0.7344\n",
      "Epoch 1406/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4264 - accuracy: 0.8471 - val_loss: 0.7638 - val_accuracy: 0.7314\n",
      "Epoch 1407/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4271 - accuracy: 0.8439 - val_loss: 0.7435 - val_accuracy: 0.7354\n",
      "Epoch 1408/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4238 - accuracy: 0.8424 - val_loss: 0.7129 - val_accuracy: 0.7383\n",
      "Epoch 1409/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4138 - accuracy: 0.8495 - val_loss: 0.6966 - val_accuracy: 0.7490\n",
      "Epoch 1410/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4325 - accuracy: 0.8419 - val_loss: 0.6911 - val_accuracy: 0.7500\n",
      "Epoch 1411/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4228 - accuracy: 0.8429 - val_loss: 0.6963 - val_accuracy: 0.7451\n",
      "Epoch 1412/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4193 - accuracy: 0.8473 - val_loss: 0.7040 - val_accuracy: 0.7383\n",
      "Epoch 1413/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4193 - accuracy: 0.8471 - val_loss: 0.7127 - val_accuracy: 0.7373\n",
      "Epoch 1414/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4258 - accuracy: 0.8436 - val_loss: 0.7090 - val_accuracy: 0.7539\n",
      "Epoch 1415/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4309 - accuracy: 0.8466 - val_loss: 0.7178 - val_accuracy: 0.7500\n",
      "Epoch 1416/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4191 - accuracy: 0.8473 - val_loss: 0.7157 - val_accuracy: 0.7520\n",
      "Epoch 1417/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4096 - accuracy: 0.8529 - val_loss: 0.6948 - val_accuracy: 0.7578\n",
      "Epoch 1418/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4256 - accuracy: 0.8466 - val_loss: 0.6749 - val_accuracy: 0.7578\n",
      "Epoch 1419/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4201 - accuracy: 0.8512 - val_loss: 0.6615 - val_accuracy: 0.7549\n",
      "Epoch 1420/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4334 - accuracy: 0.8427 - val_loss: 0.6592 - val_accuracy: 0.7549\n",
      "Epoch 1421/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4116 - accuracy: 0.8456 - val_loss: 0.6611 - val_accuracy: 0.7510\n",
      "Epoch 1422/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4220 - accuracy: 0.8466 - val_loss: 0.6635 - val_accuracy: 0.7559\n",
      "Epoch 1423/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4009 - accuracy: 0.8539 - val_loss: 0.6605 - val_accuracy: 0.7510\n",
      "Epoch 1424/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4109 - accuracy: 0.8532 - val_loss: 0.6617 - val_accuracy: 0.7529\n",
      "Epoch 1425/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4237 - accuracy: 0.8473 - val_loss: 0.6663 - val_accuracy: 0.7598\n",
      "Epoch 1426/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4153 - accuracy: 0.8483 - val_loss: 0.6868 - val_accuracy: 0.7539\n",
      "Epoch 1427/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4140 - accuracy: 0.8505 - val_loss: 0.7022 - val_accuracy: 0.7480\n",
      "Epoch 1428/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4121 - accuracy: 0.8532 - val_loss: 0.7128 - val_accuracy: 0.7490\n",
      "Epoch 1429/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4180 - accuracy: 0.8444 - val_loss: 0.7176 - val_accuracy: 0.7422\n",
      "Epoch 1430/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4149 - accuracy: 0.8478 - val_loss: 0.7165 - val_accuracy: 0.7432\n",
      "Epoch 1431/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4080 - accuracy: 0.8480 - val_loss: 0.7051 - val_accuracy: 0.7529\n",
      "Epoch 1432/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4147 - accuracy: 0.8495 - val_loss: 0.6994 - val_accuracy: 0.7578\n",
      "Epoch 1433/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4274 - accuracy: 0.8412 - val_loss: 0.6962 - val_accuracy: 0.7607\n",
      "Epoch 1434/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4133 - accuracy: 0.8544 - val_loss: 0.7016 - val_accuracy: 0.7539\n",
      "Epoch 1435/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4074 - accuracy: 0.8512 - val_loss: 0.6956 - val_accuracy: 0.7510\n",
      "Epoch 1436/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4175 - accuracy: 0.8490 - val_loss: 0.6782 - val_accuracy: 0.7549\n",
      "Epoch 1437/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4011 - accuracy: 0.8524 - val_loss: 0.6717 - val_accuracy: 0.7520\n",
      "Epoch 1438/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4332 - accuracy: 0.8422 - val_loss: 0.6821 - val_accuracy: 0.7510\n",
      "Epoch 1439/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4157 - accuracy: 0.8475 - val_loss: 0.6927 - val_accuracy: 0.7510\n",
      "Epoch 1440/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4194 - accuracy: 0.8485 - val_loss: 0.7120 - val_accuracy: 0.7520\n",
      "Epoch 1441/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4078 - accuracy: 0.8598 - val_loss: 0.7240 - val_accuracy: 0.7480\n",
      "Epoch 1442/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4301 - accuracy: 0.8446 - val_loss: 0.7097 - val_accuracy: 0.7510\n",
      "Epoch 1443/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4145 - accuracy: 0.8490 - val_loss: 0.6938 - val_accuracy: 0.7568\n",
      "Epoch 1444/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4216 - accuracy: 0.8441 - val_loss: 0.6739 - val_accuracy: 0.7500\n",
      "Epoch 1445/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4138 - accuracy: 0.8463 - val_loss: 0.6744 - val_accuracy: 0.7617\n",
      "Epoch 1446/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4161 - accuracy: 0.8485 - val_loss: 0.6944 - val_accuracy: 0.7500\n",
      "Epoch 1447/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4228 - accuracy: 0.8422 - val_loss: 0.7155 - val_accuracy: 0.7402\n",
      "Epoch 1448/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4287 - accuracy: 0.8500 - val_loss: 0.7253 - val_accuracy: 0.7402\n",
      "Epoch 1449/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4127 - accuracy: 0.8539 - val_loss: 0.7275 - val_accuracy: 0.7568\n",
      "Epoch 1450/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4170 - accuracy: 0.8524 - val_loss: 0.7236 - val_accuracy: 0.7617\n",
      "Epoch 1451/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4130 - accuracy: 0.8475 - val_loss: 0.7194 - val_accuracy: 0.7627\n",
      "Epoch 1452/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4221 - accuracy: 0.8488 - val_loss: 0.7091 - val_accuracy: 0.7549\n",
      "Epoch 1453/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4144 - accuracy: 0.8493 - val_loss: 0.6957 - val_accuracy: 0.7617\n",
      "Epoch 1454/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4134 - accuracy: 0.8539 - val_loss: 0.6913 - val_accuracy: 0.7637\n",
      "Epoch 1455/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4285 - accuracy: 0.8466 - val_loss: 0.6864 - val_accuracy: 0.7598\n",
      "Epoch 1456/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4215 - accuracy: 0.8422 - val_loss: 0.6839 - val_accuracy: 0.7588\n",
      "Epoch 1457/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4167 - accuracy: 0.8458 - val_loss: 0.6873 - val_accuracy: 0.7617\n",
      "Epoch 1458/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4149 - accuracy: 0.8439 - val_loss: 0.6874 - val_accuracy: 0.7627\n",
      "Epoch 1459/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4044 - accuracy: 0.8512 - val_loss: 0.6824 - val_accuracy: 0.7549\n",
      "Epoch 1460/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4124 - accuracy: 0.8500 - val_loss: 0.6735 - val_accuracy: 0.7568\n",
      "Epoch 1461/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4046 - accuracy: 0.8488 - val_loss: 0.6577 - val_accuracy: 0.7617\n",
      "Epoch 1462/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4023 - accuracy: 0.8576 - val_loss: 0.6450 - val_accuracy: 0.7578\n",
      "Epoch 1463/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4109 - accuracy: 0.8505 - val_loss: 0.6385 - val_accuracy: 0.7568\n",
      "Epoch 1464/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4174 - accuracy: 0.8490 - val_loss: 0.6423 - val_accuracy: 0.7598\n",
      "Epoch 1465/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4007 - accuracy: 0.8527 - val_loss: 0.6543 - val_accuracy: 0.7568\n",
      "Epoch 1466/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4001 - accuracy: 0.8502 - val_loss: 0.6714 - val_accuracy: 0.7529\n",
      "Epoch 1467/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4174 - accuracy: 0.8493 - val_loss: 0.6796 - val_accuracy: 0.7529\n",
      "Epoch 1468/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4110 - accuracy: 0.8522 - val_loss: 0.6790 - val_accuracy: 0.7578\n",
      "Epoch 1469/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4043 - accuracy: 0.8554 - val_loss: 0.6742 - val_accuracy: 0.7607\n",
      "Epoch 1470/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4163 - accuracy: 0.8468 - val_loss: 0.6758 - val_accuracy: 0.7549\n",
      "Epoch 1471/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4166 - accuracy: 0.8527 - val_loss: 0.7015 - val_accuracy: 0.7393\n",
      "Epoch 1472/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4235 - accuracy: 0.8478 - val_loss: 0.7358 - val_accuracy: 0.7070\n",
      "Epoch 1473/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4287 - accuracy: 0.8409 - val_loss: 0.7537 - val_accuracy: 0.7012\n",
      "Epoch 1474/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4173 - accuracy: 0.8490 - val_loss: 0.7361 - val_accuracy: 0.7168\n",
      "Epoch 1475/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4037 - accuracy: 0.8563 - val_loss: 0.7136 - val_accuracy: 0.7393\n",
      "Epoch 1476/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3996 - accuracy: 0.8561 - val_loss: 0.6973 - val_accuracy: 0.7529\n",
      "Epoch 1477/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4064 - accuracy: 0.8537 - val_loss: 0.6938 - val_accuracy: 0.7539\n",
      "Epoch 1478/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4034 - accuracy: 0.8585 - val_loss: 0.6866 - val_accuracy: 0.7500\n",
      "Epoch 1479/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4008 - accuracy: 0.8598 - val_loss: 0.6810 - val_accuracy: 0.7559\n",
      "Epoch 1480/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4159 - accuracy: 0.8522 - val_loss: 0.6790 - val_accuracy: 0.7559\n",
      "Epoch 1481/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4047 - accuracy: 0.8556 - val_loss: 0.6756 - val_accuracy: 0.7598\n",
      "Epoch 1482/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4048 - accuracy: 0.8568 - val_loss: 0.6788 - val_accuracy: 0.7617\n",
      "Epoch 1483/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3967 - accuracy: 0.8559 - val_loss: 0.6791 - val_accuracy: 0.7607\n",
      "Epoch 1484/1500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4177 - accuracy: 0.8434 - val_loss: 0.6825 - val_accuracy: 0.7578\n",
      "Epoch 1485/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4081 - accuracy: 0.8554 - val_loss: 0.6825 - val_accuracy: 0.7578\n",
      "Epoch 1486/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4048 - accuracy: 0.8490 - val_loss: 0.6818 - val_accuracy: 0.7529\n",
      "Epoch 1487/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3969 - accuracy: 0.8563 - val_loss: 0.6911 - val_accuracy: 0.7480\n",
      "Epoch 1488/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4020 - accuracy: 0.8561 - val_loss: 0.7192 - val_accuracy: 0.7461\n",
      "Epoch 1489/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4164 - accuracy: 0.8537 - val_loss: 0.7462 - val_accuracy: 0.7334\n",
      "Epoch 1490/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4181 - accuracy: 0.8488 - val_loss: 0.7757 - val_accuracy: 0.7266\n",
      "Epoch 1491/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4060 - accuracy: 0.8441 - val_loss: 0.7904 - val_accuracy: 0.7217\n",
      "Epoch 1492/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4140 - accuracy: 0.8519 - val_loss: 0.7893 - val_accuracy: 0.7197\n",
      "Epoch 1493/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4005 - accuracy: 0.8581 - val_loss: 0.7542 - val_accuracy: 0.7305\n",
      "Epoch 1494/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3986 - accuracy: 0.8590 - val_loss: 0.7103 - val_accuracy: 0.7412\n",
      "Epoch 1495/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4030 - accuracy: 0.8495 - val_loss: 0.6726 - val_accuracy: 0.7500\n",
      "Epoch 1496/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4179 - accuracy: 0.8468 - val_loss: 0.6684 - val_accuracy: 0.7529\n",
      "Epoch 1497/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4058 - accuracy: 0.8483 - val_loss: 0.6812 - val_accuracy: 0.7559\n",
      "Epoch 1498/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3902 - accuracy: 0.8593 - val_loss: 0.6896 - val_accuracy: 0.7471\n",
      "Epoch 1499/1500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4105 - accuracy: 0.8556 - val_loss: 0.6907 - val_accuracy: 0.7510\n",
      "Epoch 1500/1500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4142 - accuracy: 0.8495 - val_loss: 0.6868 - val_accuracy: 0.7637\n",
      "-----------------------------------------------------------------\n",
      "Training was completed in 3236.13 secs\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "History = model.fit(X_train_partial,\n",
    "                    y_train_partial,\n",
    "                    epochs=1500,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.0,\n",
    "                    validation_data=(X_val[:M_TEST], y_val[:M_TEST]),\n",
    "                    shuffle=True,\n",
    "                    verbose=1)\n",
    "\n",
    "print('-'*65)\n",
    "print(f'Training was completed in {time.time() - start:.2f} secs')\n",
    "print('-'*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 499ms/step - loss: 0.4102 - accuracy: 0.8664\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6868 - accuracy: 0.7637\n",
      "-----------------------------------------------------------------\n",
      "train accuracy = 86.6357%\n",
      "test accuracy = 76.3672%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model:\n",
    "train_loss, train_accuracy = model.evaluate(X_train_partial,\n",
    "                                       y_train_partial,\n",
    "                                       batch_size=M_TRAIN,\n",
    "                                       verbose=1)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_val[:M_TEST],\n",
    "                                     y_val[:M_TEST],\n",
    "                                     batch_size=M_TEST,\n",
    "                                     verbose=1)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_accuracy * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_accuracy * 100, 4)}%')\n",
    "\n",
    "\n",
    "# Plot the loss and accuracy curves over epochs:\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
    "axs[0].plot(History.history['loss'], color='b', label='Training loss')\n",
    "axs[0].plot(History.history['val_loss'], color='r', label='Validation loss')\n",
    "axs[0].set_title(\"Loss curves\")\n",
    "axs[0].legend(loc='best', shadow=True)\n",
    "axs[1].plot(History.history['accuracy'], color='b', label='Training accuracy')\n",
    "axs[1].plot(History.history['val_accuracy'], color='r', label='Validation accuracy')\n",
    "axs[1].set_title(\"Accuracy curves\")\n",
    "axs[1].legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.763671875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "f1_score(y_val, to_categorical(y_pred.argmax(axis=1)), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(extraction_directory + 'X_test.csv', index_col='id')\n",
    "\n",
    "X_test_downsampled = X_test.iloc[:,range(0, X_test.shape[1], 2)]\n",
    "assert X_test_downsampled.shape[1] == X_train_downsampled.shape[1]\n",
    "\n",
    "measure_length_test_downsampled = (-X_test_downsampled.T.isna()).sum().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0901792049407959\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "X_test1_np = np.zeros((measure_length_test_downsampled.shape[0], length))\n",
    "X_test_downsampled_np = X_test_downsampled.to_numpy()\n",
    "\n",
    "for ind in range(X_test_downsampled.shape[0]):\n",
    "    first_timestep = (measure_length_test_downsampled.loc[X_test_downsampled.index[ind]] - length) // 2\n",
    "    last_timestep = first_timestep + length\n",
    "    X_test1_np[ind,:] = X_test_downsampled_np[ind,first_timestep:last_timestep]\n",
    "\n",
    "X_test1 = pd.DataFrame(data=X_test1_np, index=X_test_downsampled.index)\n",
    "\n",
    "X_test_transformed_np = scaler.transform(X_test1)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_transformed_np)\n",
    "\n",
    "y_pred_class_np = y_pred.argmax(axis=1)\n",
    "\n",
    "sol = pd.DataFrame(data={'id': range(y_pred_class_np.shape[0]), 'y': y_pred_class_np})\n",
    "sol.to_csv('sol_big2.csv', columns=['id', 'y'], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2733.,    0.,    0.,  175.,    0.,    0.,  491.,    0.,    0.,\n",
       "          12.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_class_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
